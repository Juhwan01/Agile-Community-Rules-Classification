{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75351324",
   "metadata": {},
   "source": [
    "##  Cross-Encoder + LightGBM Ensemble Model\n",
    "\n",
    "This notebook builds a powerful ensemble model to determine if a comment violates a community rule.\n",
    "\n",
    "### **Methodology**\n",
    "1.  **Feature Engineering**: Creates numerical and categorical features based on EDA insights.\n",
    "2.  **Cross-Encoder Training**: A `deberta-v3-small` model is fine-tuned to understand the semantic relationship between a rule and a comment, generating a 'semantic score'.\n",
    "3.  **LightGBM Training**: An LGBM model is trained on a combination of the engineered features and the semantic score from the Cross-Encoder.\n",
    "4.  **Ensemble Pipeline**: The final model uses this two-stage process for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1781db68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU ÏÇ¨Ïö© Í∞ÄÎä•: True\n",
      "ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä ÌôïÏù∏\n",
    "print(f\"GPU ÏÇ¨Ïö© Í∞ÄÎä•: {torch.cuda.is_available()}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c83e6f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Îç∞Ïù¥ÌÑ∞ ÌòïÌÉú: (2029, 9)\n",
      "üéØ ÌÉÄÍ≤ü Î∂ÑÌè¨: {1: 1031, 0: 998}\n",
      "\n",
      "üìã Îç∞Ïù¥ÌÑ∞ ÏÉòÌîå:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>body</th>\n",
       "      <th>rule</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>positive_example_1</th>\n",
       "      <th>positive_example_2</th>\n",
       "      <th>negative_example_1</th>\n",
       "      <th>negative_example_2</th>\n",
       "      <th>rule_violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Banks don't want you to know this! Click here ...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>Futurology</td>\n",
       "      <td>If you could tell your younger self something ...</td>\n",
       "      <td>hunt for lady for jack off in neighbourhood ht...</td>\n",
       "      <td>Watch Golden Globe Awards 2017 Live Online in ...</td>\n",
       "      <td>DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SD Stream [ ENG Link 1] (http://www.sportsstre...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>soccerstreams</td>\n",
       "      <td>[I wanna kiss you all over! Stunning!](http://...</td>\n",
       "      <td>LOLGA.COM is One of the First Professional Onl...</td>\n",
       "      <td>#Rapper \\nüö®Straight Outta Cross Keys SC üö®YouTu...</td>\n",
       "      <td>[15 Amazing Hidden Features Of Google Search Y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lol. Try appealing the ban and say you won't d...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Don't break up with him or call the cops.  If ...</td>\n",
       "      <td>It'll be dismissed: https://en.wikipedia.org/w...</td>\n",
       "      <td>Where is there a site that still works where y...</td>\n",
       "      <td>Because this statement of his is true. It isn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>she will come your home open her legs with  an...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>sex</td>\n",
       "      <td>Selling Tyrande codes for 3‚Ç¨ to paypal. PM. \\n...</td>\n",
       "      <td>tight pussy watch for your cock get her at thi...</td>\n",
       "      <td>NSFW(obviously) http://spankbang.com/iy3u/vide...</td>\n",
       "      <td>Good News ::Download WhatsApp 2.16.230 APK for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>hearthstone</td>\n",
       "      <td>wow!! amazing reminds me of the old days.Well...</td>\n",
       "      <td>seek for lady for sex in around http://p77.pl/...</td>\n",
       "      <td>must be watch movie https://sites.google.com/s...</td>\n",
       "      <td>We're streaming Pokemon Veitnamese Crystal RIG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                                               body  \\\n",
       "0       0  Banks don't want you to know this! Click here ...   \n",
       "1       1  SD Stream [ ENG Link 1] (http://www.sportsstre...   \n",
       "2       2  Lol. Try appealing the ban and say you won't d...   \n",
       "3       3  she will come your home open her legs with  an...   \n",
       "4       4  code free tyrande --->>> [Imgur](http://i.imgu...   \n",
       "\n",
       "                                                rule      subreddit  \\\n",
       "0  No Advertising: Spam, referral links, unsolici...     Futurology   \n",
       "1  No Advertising: Spam, referral links, unsolici...  soccerstreams   \n",
       "2  No legal advice: Do not offer or request legal...   pcmasterrace   \n",
       "3  No Advertising: Spam, referral links, unsolici...            sex   \n",
       "4  No Advertising: Spam, referral links, unsolici...    hearthstone   \n",
       "\n",
       "                                  positive_example_1  \\\n",
       "0  If you could tell your younger self something ...   \n",
       "1  [I wanna kiss you all over! Stunning!](http://...   \n",
       "2  Don't break up with him or call the cops.  If ...   \n",
       "3  Selling Tyrande codes for 3‚Ç¨ to paypal. PM. \\n...   \n",
       "4   wow!! amazing reminds me of the old days.Well...   \n",
       "\n",
       "                                  positive_example_2  \\\n",
       "0  hunt for lady for jack off in neighbourhood ht...   \n",
       "1  LOLGA.COM is One of the First Professional Onl...   \n",
       "2  It'll be dismissed: https://en.wikipedia.org/w...   \n",
       "3  tight pussy watch for your cock get her at thi...   \n",
       "4  seek for lady for sex in around http://p77.pl/...   \n",
       "\n",
       "                                  negative_example_1  \\\n",
       "0  Watch Golden Globe Awards 2017 Live Online in ...   \n",
       "1  #Rapper \\nüö®Straight Outta Cross Keys SC üö®YouTu...   \n",
       "2  Where is there a site that still works where y...   \n",
       "3  NSFW(obviously) http://spankbang.com/iy3u/vide...   \n",
       "4  must be watch movie https://sites.google.com/s...   \n",
       "\n",
       "                                  negative_example_2  rule_violation  \n",
       "0  DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...               0  \n",
       "1  [15 Amazing Hidden Features Of Google Search Y...               0  \n",
       "2  Because this statement of his is true. It isn'...               1  \n",
       "3  Good News ::Download WhatsApp 2.16.230 APK for...               1  \n",
       "4  We're streaming Pokemon Veitnamese Crystal RIG...               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# üìä Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è Í∏∞Î≥∏ Ï†ïÎ≥¥ ÌôïÏù∏\n",
    "# ==========================================================\n",
    "# Î°úÏª¨ Í≤ΩÎ°úÏóêÏÑú ÌïôÏäµ Îç∞Ïù¥ÌÑ∞Î•º Î∂àÎü¨ÏòµÎãàÎã§.\n",
    "# If you don't have 'train.csv', create a dummy file to run the notebook\n",
    "if not os.path.exists('train.csv'):\n",
    "    dummy_data = {\n",
    "        'body': ['This is a great post!', 'Check out my website www.spam.com', 'I disagree with this rule.', 'legal advice is not allowed here', 'where can i watch the game?', 'no advertising please'],\n",
    "        'rule': ['Be nice', 'No spam', 'Follow the rules', 'No legal advice', 'No illegal content', 'No Advertising'],\n",
    "        'subreddit': ['hearthstone', 'soccerstreams', 'legaladvice', 'legaladvice', 'soccerstreams', 'sex'],\n",
    "        'rule_violation': [0, 1, 0, 1, 1, 1],\n",
    "        'positive_example_1': [np.nan, 'our product is the best', np.nan, 'asking for a lawyer is legal advice', 'youtube.com/stream', 'dont promote your onlyfans'],\n",
    "        'negative_example_1': ['thanks for sharing', np.nan, 'I love this sub', 'I am not a lawyer but...', 'what time is the match?', 'i have a question about my body']\n",
    "    }\n",
    "    train_df = pd.DataFrame(dummy_data)\n",
    "    train_df.to_csv('train.csv', index=False)\n",
    "    print(\"Dummy 'train.csv' created.\")\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "print(f\"üîç Îç∞Ïù¥ÌÑ∞ ÌòïÌÉú: {train_df.shape}\")\n",
    "print(f\"üéØ ÌÉÄÍ≤ü Î∂ÑÌè¨: {train_df['rule_violation'].value_counts().to_dict()}\")\n",
    "print(\"\\nüìã Îç∞Ïù¥ÌÑ∞ ÏÉòÌîå:\")\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a66819f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨ ÏãúÏûë...\n",
      "üìè Í∏∞Î≥∏ ÌÖçÏä§Ìä∏ ÌäπÏßï ÏÉùÏÑ± Ï§ë...\n",
      "üé® Ïä§ÌÉÄÏùº ÌäπÏßï ÏÉùÏÑ± Ï§ë...\n",
      "üîó Í∑úÏπô-ÎåìÍ∏Ä ÏÉÅÌò∏ÏûëÏö© ÌäπÏßï ÏÉùÏÑ± Ï§ë...\n",
      "‚úÖ ÌäπÏßï ÏÉùÏÑ± ÏôÑÎ£å!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# üõ†Ô∏è ÌäπÏßï ÏóîÏßÄÎãàÏñ¥ÎßÅ Ìï®Ïàò Ï†ïÏùò\n",
    "# ==========================================================\n",
    "def count_urls(text):\n",
    "    return len(re.findall(r'https?://\\S+|www\\.\\S+', str(text)))\n",
    "\n",
    "def count_exclaims(text):\n",
    "    return str(text).count('!')\n",
    "\n",
    "def count_questions(text):\n",
    "    return str(text).count('?')\n",
    "\n",
    "def upper_ratio(text):\n",
    "    s = str(text)\n",
    "    letters = [c for c in s if c.isalpha()]\n",
    "    if not letters:\n",
    "        return 0.0\n",
    "    upp = sum(1 for c in letters if c.isupper())\n",
    "    return upp / len(letters)\n",
    "\n",
    "def repeat_char_max(text):\n",
    "    longest = 1\n",
    "    last = ''\n",
    "    cur = 0\n",
    "    for ch in str(text):\n",
    "        if ch == last:\n",
    "            cur += 1\n",
    "        else:\n",
    "            longest = max(longest, cur)\n",
    "            cur = 1\n",
    "            last = ch\n",
    "    longest = max(longest, cur)\n",
    "    return longest\n",
    "\n",
    "def jaccard_similarity(text1, text2):\n",
    "    set1 = set(str(text1).lower().split())\n",
    "    set2 = set(str(text2).lower().split())\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    print(\"üìè Í∏∞Î≥∏ ÌÖçÏä§Ìä∏ ÌäπÏßï ÏÉùÏÑ± Ï§ë...\")\n",
    "    df['body_len'] = df['body'].astype(str).str.len()\n",
    "    df['rule_len'] = df['rule'].astype(str).str.len()\n",
    "    df['body_words'] = df['body'].astype(str).str.split().str.len()\n",
    "    print(\"üé® Ïä§ÌÉÄÏùº ÌäπÏßï ÏÉùÏÑ± Ï§ë...\")\n",
    "    df['url_cnt'] = df['body'].apply(count_urls)\n",
    "    df['exc_cnt'] = df['body'].apply(count_exclaims)\n",
    "    df['q_cnt'] = df['body'].apply(count_questions)\n",
    "    df['upper_rt'] = df['body'].apply(upper_ratio)\n",
    "    df['rep_run'] = df['body'].apply(repeat_char_max)\n",
    "    print(\"üîó Í∑úÏπô-ÎåìÍ∏Ä ÏÉÅÌò∏ÏûëÏö© ÌäπÏßï ÏÉùÏÑ± Ï§ë...\")\n",
    "    df['rule_body_jaccard'] = [jaccard_similarity(rule, body) for rule, body in zip(df['rule'], df['body'])]\n",
    "    print(\"‚úÖ ÌäπÏßï ÏÉùÏÑ± ÏôÑÎ£å!\")\n",
    "    return df\n",
    "\n",
    "def prepare_cross_encoder_input(rule, body, positive_ex1=None, negative_ex1=None):\n",
    "    rule_text = str(rule).strip()\n",
    "    comment_text = str(body).strip()\n",
    "    examples_text = \"\"\n",
    "    if pd.notna(positive_ex1) and str(positive_ex1).strip():\n",
    "        examples_text += f\" [Í∏çÏ†ïÏòàÏãú] {str(positive_ex1).strip()}\"\n",
    "    if pd.notna(negative_ex1) and str(negative_ex1).strip():\n",
    "        examples_text += f\" [Î∂ÄÏ†ïÏòàÏãú] {str(negative_ex1).strip()}\"\n",
    "    full_input = f\"[Í∑úÏπô] {rule_text}{examples_text} [ÎåìÍ∏Ä] {comment_text}\"\n",
    "    return full_input\n",
    "\n",
    "# ==========================================================\n",
    "# üìä Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨ Î∞è ÌäπÏßï ÏÉùÏÑ± Ïã§Ìñâ\n",
    "# ==========================================================\n",
    "print(\"üîß Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨ ÏãúÏûë...\")\n",
    "train_df_featured = create_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb6d6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Cross-Encoder ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ Ï§ë...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2029/2029 [00:00<00:00, 20562.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 2029Í∞úÏùò Cross-Encoder ÏûÖÎ†• Ïåç Ï§ÄÎπÑ ÏôÑÎ£å\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ü§ñ Cross-Encoder ÏûÖÎ†• Ï§ÄÎπÑ\n",
    "# ==========================================================\n",
    "print(\"üîÑ Cross-Encoder ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ Ï§ë...\")\n",
    "ce_inputs = []\n",
    "labels = []\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"CE ÏûÖÎ†• Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨\"):\n",
    "    ce_input = prepare_cross_encoder_input(\n",
    "        row['rule'], row['body'],\n",
    "        row.get('positive_example_1'),\n",
    "        row.get('negative_example_1')\n",
    "    )\n",
    "    ce_inputs.append(ce_input)\n",
    "    labels.append(int(row['rule_violation']))\n",
    "\n",
    "ce_inputs = np.array(ce_inputs)\n",
    "labels = np.array(labels)\n",
    "print(f\"‚úÖ {len(ce_inputs)}Í∞úÏùò Cross-Encoder ÏûÖÎ†• Ïåç Ï§ÄÎπÑ ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45bea179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèóÔ∏è Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏúºÎ°ú Cross-Encoder Î™®Îç∏ ÌõàÎ†® ÏãúÏûë!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Ï†ÑÏ≤¥ ÌõàÎ†® ÏòàÏãú ÏÉùÏÑ± Ï§ë...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÏµúÏ¢Ö ÌõàÎ†® Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2029/2029 [00:00<00:00, 137401.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ ÏµúÏ¢Ö Î™®Îç∏ ÌõàÎ†® (ÏóêÌè≠: 4, Î∞∞Ïπò: 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e67fafa29cc41c2ac621fed5fe2d2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8acb4783c7074280a3748278d8fca1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94283179ce542ea8747a136dfe4c673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100a05d29e444fa08bc33888b907eaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fd200eb65e458d84c16d5cd3b60c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Î™®Îç∏ÏùÑ ./model_output/final_cross_encoder_model Í≤ΩÎ°úÏóê Ï†ÄÏû• Ï§ë...\n",
      "‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# üèóÔ∏è 1Îã®Í≥Ñ: Cross-Encoder Î™®Îç∏ ÌõàÎ†® (Ïò§Î•ò ÏàòÏ†ï ÏµúÏ¢ÖÎ≥∏)\n",
    "# ==========================================================\n",
    "from sentence_transformers import CrossEncoder, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"üèóÔ∏è Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏúºÎ°ú Cross-Encoder Î™®Îç∏ ÌõàÎ†® ÏãúÏûë!\")\n",
    "output_model_path = './model_output/final_cross_encoder_model'\n",
    "os.makedirs(output_model_path, exist_ok=True)\n",
    "\n",
    "model_name = 'microsoft/deberta-v3-small'\n",
    "cross_encoder_model = CrossEncoder(model_name, num_labels=1, device=device)\n",
    "\n",
    "\n",
    "# ‚ú®‚ú®‚ú® Ïù¥ Î∂ÄÎ∂ÑÏù¥ Ï†úÍ∞Ä Ïã§ÏàòÎ°ú Îπ†Îú®Î†∏Îçò ÏΩîÎìúÏûÖÎãàÎã§! ‚ú®‚ú®‚ú®\n",
    "# Cross-EncoderÍ∞Ä ÌïôÏäµÌï† Ïàò ÏûàÎäî InputExample ÌòïÌÉúÎ°ú Îç∞Ïù¥ÌÑ∞Î•º Î≥ÄÌôòÌï©ÎãàÎã§.\n",
    "print(\"üìö Ï†ÑÏ≤¥ ÌõàÎ†® ÏòàÏãú ÏÉùÏÑ± Ï§ë...\")\n",
    "train_examples = []\n",
    "for i in tqdm(range(len(ce_inputs)), desc=\"ÏµúÏ¢Ö ÌõàÎ†® Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨\"):\n",
    "    ce_input = ce_inputs[i]\n",
    "    if '[ÎåìÍ∏Ä]' in ce_input:\n",
    "        rule_part, comment_part = ce_input.split('[ÎåìÍ∏Ä]', 1)\n",
    "    else: # ÎßåÏïΩ '[ÎåìÍ∏Ä]' Íµ¨Î∂ÑÏûêÍ∞Ä ÏóÜÎäî Í≤ΩÏö∞Ïóê ÎåÄÌïú ÎåÄÎπÑ\n",
    "        rule_part, comment_part = ce_input, \"\"\n",
    "    \n",
    "    train_examples.append(\n",
    "        InputExample(texts=[rule_part.strip(), comment_part.strip()], label=float(labels[i]))\n",
    "    )\n",
    "# ‚ú®‚ú®‚ú® Ïó¨Í∏∞ÍπåÏßÄÍ∞Ä ÎàÑÎùΩÎêú Î∂ÄÎ∂ÑÏù¥ÏóàÏäµÎãàÎã§. ‚ú®‚ú®‚ú®\n",
    "\n",
    "\n",
    "# Ïù¥Ï†ú train_examplesÍ∞Ä Ï†ïÏÉÅÏ†ÅÏúºÎ°ú ÏÉùÏÑ±ÎêòÏóàÏúºÎØÄÎ°ú DataLoaderÎ•º ÎßåÎì§ Ïàò ÏûàÏäµÎãàÎã§.\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "warmup_steps = max(1, int(len(train_dataloader) * 0.1))\n",
    "\n",
    "print(f\"üöÄ ÏµúÏ¢Ö Î™®Îç∏ ÌõàÎ†® (ÏóêÌè≠: 4, Î∞∞Ïπò: 16)\")\n",
    "\n",
    "# 1. fit Ìï®ÏàòÏóêÏÑúÎäî Ï†ÄÏû• Í¥ÄÎ†® ÏòµÏÖòÏùÑ Ï†úÍ±∞Ìï©ÎãàÎã§.\n",
    "cross_encoder_model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    epochs=4,\n",
    "    warmup_steps=warmup_steps,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# 2. ÌïôÏäµÏù¥ ÏôÑÎ£åÎêú ÌõÑ, .save() Î©îÏÑúÎìúÎ•º Î™ÖÏãúÏ†ÅÏúºÎ°ú Ìò∏Ï∂úÌïòÏó¨ Ï†ÄÏû•Ìï©ÎãàÎã§.\n",
    "print(f\"üíæ Î™®Îç∏ÏùÑ {output_model_path} Í≤ΩÎ°úÏóê Ï†ÄÏû• Ï§ë...\")\n",
    "cross_encoder_model.save(output_model_path)\n",
    "print(\"‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824e1894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÆ Cross-EncoderÎ•º ÏÇ¨Ïö©ÌïòÏó¨ semantic score ÏòàÏ∏° Ï§ë...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÏòàÏ∏°Ïö© Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2029/2029 [00:00<00:00, 117264.59it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad0b2bb907245f5b2006cffd764a7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Semantic score ('ce_score')Í∞Ä ÌäπÏßïÏóê Ï∂îÍ∞ÄÎêòÏóàÏäµÎãàÎã§.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>rule</th>\n",
       "      <th>ce_score</th>\n",
       "      <th>rule_violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Banks don't want you to know this! Click here ...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>0.073306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SD Stream [ ENG Link 1] (http://www.sportsstre...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>0.030508</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lol. Try appealing the ban and say you won't d...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>0.956159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she will come your home open her legs with  an...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>0.968073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>0.966402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  \\\n",
       "0  Banks don't want you to know this! Click here ...   \n",
       "1  SD Stream [ ENG Link 1] (http://www.sportsstre...   \n",
       "2  Lol. Try appealing the ban and say you won't d...   \n",
       "3  she will come your home open her legs with  an...   \n",
       "4  code free tyrande --->>> [Imgur](http://i.imgu...   \n",
       "\n",
       "                                                rule  ce_score  rule_violation  \n",
       "0  No Advertising: Spam, referral links, unsolici...  0.073306               0  \n",
       "1  No Advertising: Spam, referral links, unsolici...  0.030508               0  \n",
       "2  No legal advice: Do not offer or request legal...  0.956159               1  \n",
       "3  No Advertising: Spam, referral links, unsolici...  0.968073               1  \n",
       "4  No Advertising: Spam, referral links, unsolici...  0.966402               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ‚ú® NEW: =======================================================\n",
    "# ü§ñ 2Îã®Í≥Ñ Ï§ÄÎπÑ: Cross-EncoderÎ°ú Semantic Feature ÏÉùÏÑ±\n",
    "# ==========================================================\n",
    "print(\"üîÆ Cross-EncoderÎ•º ÏÇ¨Ïö©ÌïòÏó¨ semantic score ÏòàÏ∏° Ï§ë...\")\n",
    "\n",
    "# ÌõàÎ†®Îêú Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÏòàÏ∏°ÏùÑ ÏàòÌñâÌïòÍ∏∞ ÏúÑÌïú ÏûÖÎ†• ÌòïÏãùÏúºÎ°ú Î≥ÄÌôò\n",
    "predict_examples = []\n",
    "for i in tqdm(range(len(ce_inputs)), desc=\"ÏòàÏ∏°Ïö© Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò\"):\n",
    "    ce_input = ce_inputs[i]\n",
    "    if '[ÎåìÍ∏Ä]' in ce_input:\n",
    "        rule_part, comment_part = ce_input.split('[ÎåìÍ∏Ä]', 1)\n",
    "    else:\n",
    "        rule_part, comment_part = ce_input, \"\"\n",
    "    predict_examples.append([rule_part.strip(), comment_part.strip()])\n",
    "\n",
    "# ÏòàÏ∏° ÏàòÌñâ (raw logit scores)\n",
    "ce_predictions = cross_encoder_model.predict(predict_examples, show_progress_bar=True)\n",
    "\n",
    "# ÏòàÏ∏° Ï†êÏàòÎ•º DataFrameÏùò ÏÉàÎ°úÏö¥ Ïª¨ÎüºÏúºÎ°ú Ï∂îÍ∞Ä\n",
    "train_df_featured['ce_score'] = ce_predictions\n",
    "print(\"‚úÖ Semantic score ('ce_score')Í∞Ä ÌäπÏßïÏóê Ï∂îÍ∞ÄÎêòÏóàÏäµÎãàÎã§.\")\n",
    "display(train_df_featured[['body', 'rule', 'ce_score', 'rule_violation']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c89ded25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß LGBM Î™®Îç∏ÏùÑ ÏúÑÌïú ÌäπÏßï Ïä§ÏºÄÏùºÎßÅ Î∞è Ïù∏ÏΩîÎî© Ï§ë...\n",
      "üî¢ 10Í∞úÏùò ÏàòÏπò ÌäπÏßï Ïä§ÏºÄÏùºÎßÅ ÏôÑÎ£å.\n",
      "üìã 1Í∞úÏùò Î≤îÏ£ºÌòï ÌäπÏßï Ïõê-Ìï´ Ïù∏ÏΩîÎî© ÏôÑÎ£å.\n",
      "‚úÖ LGBM ÌõàÎ†® Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ ÏôÑÎ£å. ÏµúÏ¢Ö ÌòïÌÉú: (2029, 110)\n"
     ]
    }
   ],
   "source": [
    "# ‚ú® NEW: =======================================================\n",
    "# üõ†Ô∏è 2Îã®Í≥Ñ Ï§ÄÎπÑ: LGBMÏùÑ ÏúÑÌïú Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ\n",
    "# ==========================================================\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "print(\"üîß LGBM Î™®Îç∏ÏùÑ ÏúÑÌïú ÌäπÏßï Ïä§ÏºÄÏùºÎßÅ Î∞è Ïù∏ÏΩîÎî© Ï§ë...\")\n",
    "\n",
    "# 1. ÏàòÏπò ÌäπÏßï (Numerical Features)\n",
    "numerical_cols = [\n",
    "    'body_len', 'rule_len', 'body_words', 'url_cnt', 'exc_cnt', 'q_cnt',\n",
    "    'upper_rt', 'rep_run', 'rule_body_jaccard', \n",
    "    'ce_score' # Cross-Encoder ÏòàÏ∏° Ï†êÏàò Ìè¨Ìï®!\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "numerical_features = scaler.fit_transform(train_df_featured[numerical_cols])\n",
    "print(f\"üî¢ {len(numerical_cols)}Í∞úÏùò ÏàòÏπò ÌäπÏßï Ïä§ÏºÄÏùºÎßÅ ÏôÑÎ£å.\")\n",
    "\n",
    "# 2. Î≤îÏ£ºÌòï ÌäπÏßï (Categorical Features) - EDA Ïù∏ÏÇ¨Ïù¥Ìä∏ Î∞òÏòÅ!\n",
    "categorical_cols = ['subreddit']\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "categorical_features = onehot_encoder.fit_transform(train_df_featured[categorical_cols])\n",
    "print(f\"üìã {len(categorical_cols)}Í∞úÏùò Î≤îÏ£ºÌòï ÌäπÏßï Ïõê-Ìï´ Ïù∏ÏΩîÎî© ÏôÑÎ£å.\")\n",
    "\n",
    "# 3. Î™®Îì† ÌäπÏßï Í≤∞Ìï©\n",
    "X_lgbm = hstack([numerical_features, categorical_features])\n",
    "y_lgbm = train_df_featured['rule_violation'].values\n",
    "\n",
    "print(f\"‚úÖ LGBM ÌõàÎ†® Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ ÏôÑÎ£å. ÏµúÏ¢Ö ÌòïÌÉú: {X_lgbm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c780c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ LightGBM Î™®Îç∏ ÌõàÎ†® ÏãúÏûë...\n",
      "[LightGBM] [Info] Number of positive: 1031, number of negative: 998\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 2029, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508132 -> initscore=0.032531\n",
      "[LightGBM] [Info] Start training from score 0.032531\n",
      "‚úÖ LightGBM Î™®Îç∏ ÌõàÎ†® ÏôÑÎ£å!\n"
     ]
    }
   ],
   "source": [
    "# ‚ú® NEW: =======================================================\n",
    "# üèóÔ∏è 2Îã®Í≥Ñ: LightGBM Î™®Îç∏ ÌõàÎ†®\n",
    "# ==========================================================\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(\"üöÄ LightGBM Î™®Îç∏ ÌõàÎ†® ÏãúÏûë...\")\n",
    "\n",
    "lgbm_model = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    metric='auc',\n",
    "    n_estimators=1000, # Ï°∞Í∏∞ Ï¢ÖÎ£åÎ•º ÏÇ¨Ïö©ÌïòÎØÄÎ°ú ÎÑâÎÑâÌïòÍ≤å ÏÑ§Ï†ï\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8\n",
    ")\n",
    "\n",
    "# LGBM ÌõàÎ†®\n",
    "lgbm_model.fit(X_lgbm, y_lgbm, \n",
    "             eval_set=[(X_lgbm, y_lgbm)],\n",
    "             eval_metric='auc',\n",
    "             callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "\n",
    "print(\"‚úÖ LightGBM Î™®Îç∏ ÌõàÎ†® ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a93bb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Î™®Îç∏ Î∞è Ï†ÑÏ≤òÎ¶¨ Í∞ùÏ≤¥ Ï†ÄÏû• Ï§ë...\n",
      "‚úÖ Cross-Encoder Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: /workspace/Agile-Community-Rules-Classification/model_output/final_cross_encoder_model\n",
      "‚úÖ LGBM Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: ./model_output/lgbm_model.pkl\n",
      "‚úÖ Scaler Ï†ÄÏû• ÏôÑÎ£å: ./model_output/scaler.pkl\n",
      "‚úÖ OneHotEncoder Ï†ÄÏû• ÏôÑÎ£å: ./model_output/onehot_encoder.pkl\n",
      "‚úÖ ÏàòÏπò ÌäπÏßï Ïª¨ÎüºÎ™Ö Ï†ÄÏû• ÏôÑÎ£å: ./model_output/numerical_cols.pkl\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# üíæ ÏµúÏ¢Ö Î™®Îç∏ Î∞è Ï†ÑÏ≤òÎ¶¨ Í∞ùÏ≤¥ Ï†ÄÏû•\n",
    "# ==========================================================\n",
    "print(\"üíæ Î™®Îç∏ Î∞è Ï†ÑÏ≤òÎ¶¨ Í∞ùÏ≤¥ Ï†ÄÏû• Ï§ë...\")\n",
    "output_dir = './model_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 1. Cross-Encoder Î™®Îç∏ÏùÄ Ïù¥ÎØ∏ output_pathÏóê Ï†ÄÏû•Îê®\n",
    "print(f\"‚úÖ Cross-Encoder Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {os.path.abspath(output_model_path)}\")\n",
    "\n",
    "# ‚ú® NEW: 2. LGBM Î™®Îç∏ Ï†ÄÏû•\n",
    "joblib.dump(lgbm_model, os.path.join(output_dir, 'lgbm_model.pkl'))\n",
    "print(f\"‚úÖ LGBM Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {os.path.join(output_dir, 'lgbm_model.pkl')}\")\n",
    "\n",
    "# 3. Scaler Ï†ÄÏû•\n",
    "joblib.dump(scaler, os.path.join(output_dir, 'scaler.pkl'))\n",
    "print(f\"‚úÖ Scaler Ï†ÄÏû• ÏôÑÎ£å: {os.path.join(output_dir, 'scaler.pkl')}\")\n",
    "\n",
    "# ‚ú® NEW: 4. OneHotEncoder Ï†ÄÏû•\n",
    "joblib.dump(onehot_encoder, os.path.join(output_dir, 'onehot_encoder.pkl'))\n",
    "print(f\"‚úÖ OneHotEncoder Ï†ÄÏû• ÏôÑÎ£å: {os.path.join(output_dir, 'onehot_encoder.pkl')}\")\n",
    "\n",
    "# 5. ÏàòÏπò ÌäπÏßï Ïª¨ÎüºÎ™Ö Ï†ÄÏû•\n",
    "with open(os.path.join(output_dir, 'numerical_cols.pkl'), 'wb') as f:\n",
    "    pickle.dump(numerical_cols, f)\n",
    "print(f\"‚úÖ ÏàòÏπò ÌäπÏßï Ïª¨ÎüºÎ™Ö Ï†ÄÏû• ÏôÑÎ£å: {os.path.join(output_dir, 'numerical_cols.pkl')}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75351324",
   "metadata": {},
   "source": [
    "##  Cross-Encoder + LightGBM Ensemble Model\n",
    "\n",
    "This notebook builds a powerful ensemble model to determine if a comment violates a community rule.\n",
    "\n",
    "### **Methodology**\n",
    "1.  **Feature Engineering**: Creates numerical and categorical features based on EDA insights.\n",
    "2.  **Cross-Encoder Training**: A `deberta-v3-small` model is fine-tuned to understand the semantic relationship between a rule and a comment, generating a 'semantic score'.\n",
    "3.  **LightGBM Training**: An LGBM model is trained on a combination of the engineered features and the semantic score from the Cross-Encoder.\n",
    "4.  **Ensemble Pipeline**: The final model uses this two-stage process for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1781db68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU ì‚¬ìš© ê°€ëŠ¥: True\n",
      "ì‚¬ìš© ë””ë°”ì´ìŠ¤: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "print(f\"GPU ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c83e6f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ë°ì´í„° í˜•íƒœ: (2029, 9)\n",
      "ğŸ¯ íƒ€ê²Ÿ ë¶„í¬: {1: 1031, 0: 998}\n",
      "\n",
      "ğŸ“‹ ë°ì´í„° ìƒ˜í”Œ:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>body</th>\n",
       "      <th>rule</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>positive_example_1</th>\n",
       "      <th>positive_example_2</th>\n",
       "      <th>negative_example_1</th>\n",
       "      <th>negative_example_2</th>\n",
       "      <th>rule_violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Banks don't want you to know this! Click here ...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>Futurology</td>\n",
       "      <td>If you could tell your younger self something ...</td>\n",
       "      <td>hunt for lady for jack off in neighbourhood ht...</td>\n",
       "      <td>Watch Golden Globe Awards 2017 Live Online in ...</td>\n",
       "      <td>DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SD Stream [ ENG Link 1] (http://www.sportsstre...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>soccerstreams</td>\n",
       "      <td>[I wanna kiss you all over! Stunning!](http://...</td>\n",
       "      <td>LOLGA.COM is One of the First Professional Onl...</td>\n",
       "      <td>#Rapper \\nğŸš¨Straight Outta Cross Keys SC ğŸš¨YouTu...</td>\n",
       "      <td>[15 Amazing Hidden Features Of Google Search Y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lol. Try appealing the ban and say you won't d...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Don't break up with him or call the cops.  If ...</td>\n",
       "      <td>It'll be dismissed: https://en.wikipedia.org/w...</td>\n",
       "      <td>Where is there a site that still works where y...</td>\n",
       "      <td>Because this statement of his is true. It isn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>she will come your home open her legs with  an...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>sex</td>\n",
       "      <td>Selling Tyrande codes for 3â‚¬ to paypal. PM. \\n...</td>\n",
       "      <td>tight pussy watch for your cock get her at thi...</td>\n",
       "      <td>NSFW(obviously) http://spankbang.com/iy3u/vide...</td>\n",
       "      <td>Good News ::Download WhatsApp 2.16.230 APK for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>hearthstone</td>\n",
       "      <td>wow!! amazing reminds me of the old days.Well...</td>\n",
       "      <td>seek for lady for sex in around http://p77.pl/...</td>\n",
       "      <td>must be watch movie https://sites.google.com/s...</td>\n",
       "      <td>We're streaming Pokemon Veitnamese Crystal RIG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                                               body  \\\n",
       "0       0  Banks don't want you to know this! Click here ...   \n",
       "1       1  SD Stream [ ENG Link 1] (http://www.sportsstre...   \n",
       "2       2  Lol. Try appealing the ban and say you won't d...   \n",
       "3       3  she will come your home open her legs with  an...   \n",
       "4       4  code free tyrande --->>> [Imgur](http://i.imgu...   \n",
       "\n",
       "                                                rule      subreddit  \\\n",
       "0  No Advertising: Spam, referral links, unsolici...     Futurology   \n",
       "1  No Advertising: Spam, referral links, unsolici...  soccerstreams   \n",
       "2  No legal advice: Do not offer or request legal...   pcmasterrace   \n",
       "3  No Advertising: Spam, referral links, unsolici...            sex   \n",
       "4  No Advertising: Spam, referral links, unsolici...    hearthstone   \n",
       "\n",
       "                                  positive_example_1  \\\n",
       "0  If you could tell your younger self something ...   \n",
       "1  [I wanna kiss you all over! Stunning!](http://...   \n",
       "2  Don't break up with him or call the cops.  If ...   \n",
       "3  Selling Tyrande codes for 3â‚¬ to paypal. PM. \\n...   \n",
       "4   wow!! amazing reminds me of the old days.Well...   \n",
       "\n",
       "                                  positive_example_2  \\\n",
       "0  hunt for lady for jack off in neighbourhood ht...   \n",
       "1  LOLGA.COM is One of the First Professional Onl...   \n",
       "2  It'll be dismissed: https://en.wikipedia.org/w...   \n",
       "3  tight pussy watch for your cock get her at thi...   \n",
       "4  seek for lady for sex in around http://p77.pl/...   \n",
       "\n",
       "                                  negative_example_1  \\\n",
       "0  Watch Golden Globe Awards 2017 Live Online in ...   \n",
       "1  #Rapper \\nğŸš¨Straight Outta Cross Keys SC ğŸš¨YouTu...   \n",
       "2  Where is there a site that still works where y...   \n",
       "3  NSFW(obviously) http://spankbang.com/iy3u/vide...   \n",
       "4  must be watch movie https://sites.google.com/s...   \n",
       "\n",
       "                                  negative_example_2  rule_violation  \n",
       "0  DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...               0  \n",
       "1  [15 Amazing Hidden Features Of Google Search Y...               0  \n",
       "2  Because this statement of his is true. It isn'...               1  \n",
       "3  Good News ::Download WhatsApp 2.16.230 APK for...               1  \n",
       "4  We're streaming Pokemon Veitnamese Crystal RIG...               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ğŸ“Š ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì •ë³´ í™•ì¸\n",
    "# ==========================================================\n",
    "# ë¡œì»¬ ê²½ë¡œì—ì„œ í•™ìŠµ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "# If you don't have 'train.csv', create a dummy file to run the notebook\n",
    "if not os.path.exists('train.csv'):\n",
    "    dummy_data = {\n",
    "        'body': ['This is a great post!', 'Check out my website www.spam.com', 'I disagree with this rule.', 'legal advice is not allowed here', 'where can i watch the game?', 'no advertising please'],\n",
    "        'rule': ['Be nice', 'No spam', 'Follow the rules', 'No legal advice', 'No illegal content', 'No Advertising'],\n",
    "        'subreddit': ['hearthstone', 'soccerstreams', 'legaladvice', 'legaladvice', 'soccerstreams', 'sex'],\n",
    "        'rule_violation': [0, 1, 0, 1, 1, 1],\n",
    "        'positive_example_1': [np.nan, 'our product is the best', np.nan, 'asking for a lawyer is legal advice', 'youtube.com/stream', 'dont promote your onlyfans'],\n",
    "        'negative_example_1': ['thanks for sharing', np.nan, 'I love this sub', 'I am not a lawyer but...', 'what time is the match?', 'i have a question about my body']\n",
    "    }\n",
    "    train_df = pd.DataFrame(dummy_data)\n",
    "    train_df.to_csv('train.csv', index=False)\n",
    "    print(\"Dummy 'train.csv' created.\")\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "print(f\"ğŸ” ë°ì´í„° í˜•íƒœ: {train_df.shape}\")\n",
    "print(f\"ğŸ¯ íƒ€ê²Ÿ ë¶„í¬: {train_df['rule_violation'].value_counts().to_dict()}\")\n",
    "print(\"\\nğŸ“‹ ë°ì´í„° ìƒ˜í”Œ:\")\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a66819f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...\n",
      "ğŸ“ ê¸°ë³¸ í…ìŠ¤íŠ¸ íŠ¹ì§• ìƒì„± ì¤‘...\n",
      "ğŸ¨ ìŠ¤íƒ€ì¼ íŠ¹ì§• ìƒì„± ì¤‘...\n",
      "ğŸ”— ê·œì¹™-ëŒ“ê¸€ ìƒí˜¸ì‘ìš© íŠ¹ì§• ìƒì„± ì¤‘...\n",
      "âœ… íŠ¹ì§• ìƒì„± ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ğŸ› ï¸ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§ í•¨ìˆ˜ ì •ì˜\n",
    "# ==========================================================\n",
    "def count_urls(text):\n",
    "    return len(re.findall(r'https?://\\S+|www\\.\\S+', str(text)))\n",
    "\n",
    "def count_exclaims(text):\n",
    "    return str(text).count('!')\n",
    "\n",
    "def count_questions(text):\n",
    "    return str(text).count('?')\n",
    "\n",
    "def upper_ratio(text):\n",
    "    s = str(text)\n",
    "    letters = [c for c in s if c.isalpha()]\n",
    "    if not letters:\n",
    "        return 0.0\n",
    "    upp = sum(1 for c in letters if c.isupper())\n",
    "    return upp / len(letters)\n",
    "\n",
    "def repeat_char_max(text):\n",
    "    longest = 1\n",
    "    last = ''\n",
    "    cur = 0\n",
    "    for ch in str(text):\n",
    "        if ch == last:\n",
    "            cur += 1\n",
    "        else:\n",
    "            longest = max(longest, cur)\n",
    "            cur = 1\n",
    "            last = ch\n",
    "    longest = max(longest, cur)\n",
    "    return longest\n",
    "\n",
    "def jaccard_similarity(text1, text2):\n",
    "    set1 = set(str(text1).lower().split())\n",
    "    set2 = set(str(text2).lower().split())\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    print(\"ğŸ“ ê¸°ë³¸ í…ìŠ¤íŠ¸ íŠ¹ì§• ìƒì„± ì¤‘...\")\n",
    "    df['body_len'] = df['body'].astype(str).str.len()\n",
    "    df['rule_len'] = df['rule'].astype(str).str.len()\n",
    "    df['body_words'] = df['body'].astype(str).str.split().str.len()\n",
    "    print(\"ğŸ¨ ìŠ¤íƒ€ì¼ íŠ¹ì§• ìƒì„± ì¤‘...\")\n",
    "    df['url_cnt'] = df['body'].apply(count_urls)\n",
    "    df['exc_cnt'] = df['body'].apply(count_exclaims)\n",
    "    df['q_cnt'] = df['body'].apply(count_questions)\n",
    "    df['upper_rt'] = df['body'].apply(upper_ratio)\n",
    "    df['rep_run'] = df['body'].apply(repeat_char_max)\n",
    "    print(\"ğŸ”— ê·œì¹™-ëŒ“ê¸€ ìƒí˜¸ì‘ìš© íŠ¹ì§• ìƒì„± ì¤‘...\")\n",
    "    df['rule_body_jaccard'] = [jaccard_similarity(rule, body) for rule, body in zip(df['rule'], df['body'])]\n",
    "    print(\"âœ… íŠ¹ì§• ìƒì„± ì™„ë£Œ!\")\n",
    "    return df\n",
    "\n",
    "def prepare_cross_encoder_input(rule, body, positive_ex1=None, negative_ex1=None):\n",
    "    rule_text = str(rule).strip()\n",
    "    comment_text = str(body).strip()\n",
    "    examples_text = \"\"\n",
    "    if pd.notna(positive_ex1) and str(positive_ex1).strip():\n",
    "        examples_text += f\" [ê¸ì •ì˜ˆì‹œ] {str(positive_ex1).strip()}\"\n",
    "    if pd.notna(negative_ex1) and str(negative_ex1).strip():\n",
    "        examples_text += f\" [ë¶€ì •ì˜ˆì‹œ] {str(negative_ex1).strip()}\"\n",
    "    full_input = f\"[ê·œì¹™] {rule_text}{examples_text} [ëŒ“ê¸€] {comment_text}\"\n",
    "    return full_input\n",
    "\n",
    "# ==========================================================\n",
    "# ğŸ“Š ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì§• ìƒì„± ì‹¤í–‰\n",
    "# ==========================================================\n",
    "print(\"ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...\")\n",
    "train_df_featured = create_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb6d6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Cross-Encoder ì…ë ¥ ë°ì´í„° ì¤€ë¹„ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE ì…ë ¥ ë°ì´í„° ì²˜ë¦¬: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2029/2029 [00:00<00:00, 20562.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 2029ê°œì˜ Cross-Encoder ì…ë ¥ ìŒ ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ğŸ¤– Cross-Encoder ì…ë ¥ ì¤€ë¹„\n",
    "# ==========================================================\n",
    "print(\"ğŸ”„ Cross-Encoder ì…ë ¥ ë°ì´í„° ì¤€ë¹„ ì¤‘...\")\n",
    "ce_inputs = []\n",
    "labels = []\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"CE ì…ë ¥ ë°ì´í„° ì²˜ë¦¬\"):\n",
    "    ce_input = prepare_cross_encoder_input(\n",
    "        row['rule'], row['body'],\n",
    "        row.get('positive_example_1'),\n",
    "        row.get('negative_example_1')\n",
    "    )\n",
    "    ce_inputs.append(ce_input)\n",
    "    labels.append(int(row['rule_violation']))\n",
    "\n",
    "ce_inputs = np.array(ce_inputs)\n",
    "labels = np.array(labels)\n",
    "print(f\"âœ… {len(ce_inputs)}ê°œì˜ Cross-Encoder ì…ë ¥ ìŒ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45bea179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ï¸ ì „ì²´ ë°ì´í„°ì…‹ìœ¼ë¡œ Cross-Encoder ëª¨ë¸ í›ˆë ¨ ì‹œì‘!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š ì „ì²´ í›ˆë ¨ ì˜ˆì‹œ ìƒì„± ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ìµœì¢… í›ˆë ¨ ë°ì´í„° ì²˜ë¦¬: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2029/2029 [00:00<00:00, 137401.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ìµœì¢… ëª¨ë¸ í›ˆë ¨ (ì—í­: 4, ë°°ì¹˜: 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e67fafa29cc41c2ac621fed5fe2d2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8acb4783c7074280a3748278d8fca1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94283179ce542ea8747a136dfe4c673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100a05d29e444fa08bc33888b907eaa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fd200eb65e458d84c16d5cd3b60c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ ëª¨ë¸ì„ ./model_output/final_cross_encoder_model ê²½ë¡œì— ì €ì¥ ì¤‘...\n",
      "âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ğŸ—ï¸ 1ë‹¨ê³„: Cross-Encoder ëª¨ë¸ í›ˆë ¨ (ì˜¤ë¥˜ ìˆ˜ì • ìµœì¢…ë³¸)\n",
    "# ==========================================================\n",
    "from sentence_transformers import CrossEncoder, InputExample\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"ğŸ—ï¸ ì „ì²´ ë°ì´í„°ì…‹ìœ¼ë¡œ Cross-Encoder ëª¨ë¸ í›ˆë ¨ ì‹œì‘!\")\n",
    "output_model_path = './model_output/final_cross_encoder_model'\n",
    "os.makedirs(output_model_path, exist_ok=True)\n",
    "\n",
    "model_name = 'microsoft/deberta-v3-small'\n",
    "cross_encoder_model = CrossEncoder(model_name, num_labels=1, device=device)\n",
    "\n",
    "\n",
    "# âœ¨âœ¨âœ¨ ì´ ë¶€ë¶„ì´ ì œê°€ ì‹¤ìˆ˜ë¡œ ë¹ ëœ¨ë ¸ë˜ ì½”ë“œì…ë‹ˆë‹¤! âœ¨âœ¨âœ¨\n",
    "# Cross-Encoderê°€ í•™ìŠµí•  ìˆ˜ ìˆëŠ” InputExample í˜•íƒœë¡œ ë°ì´í„°ë¥¼ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "print(\"ğŸ“š ì „ì²´ í›ˆë ¨ ì˜ˆì‹œ ìƒì„± ì¤‘...\")\n",
    "train_examples = []\n",
    "for i in tqdm(range(len(ce_inputs)), desc=\"ìµœì¢… í›ˆë ¨ ë°ì´í„° ì²˜ë¦¬\"):\n",
    "    ce_input = ce_inputs[i]\n",
    "    if '[ëŒ“ê¸€]' in ce_input:\n",
    "        rule_part, comment_part = ce_input.split('[ëŒ“ê¸€]', 1)\n",
    "    else: # ë§Œì•½ '[ëŒ“ê¸€]' êµ¬ë¶„ìê°€ ì—†ëŠ” ê²½ìš°ì— ëŒ€í•œ ëŒ€ë¹„\n",
    "        rule_part, comment_part = ce_input, \"\"\n",
    "    \n",
    "    train_examples.append(\n",
    "        InputExample(texts=[rule_part.strip(), comment_part.strip()], label=float(labels[i]))\n",
    "    )\n",
    "# âœ¨âœ¨âœ¨ ì—¬ê¸°ê¹Œì§€ê°€ ëˆ„ë½ëœ ë¶€ë¶„ì´ì—ˆìŠµë‹ˆë‹¤. âœ¨âœ¨âœ¨\n",
    "\n",
    "\n",
    "# ì´ì œ train_examplesê°€ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìœ¼ë¯€ë¡œ DataLoaderë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "warmup_steps = max(1, int(len(train_dataloader) * 0.1))\n",
    "\n",
    "print(f\"ğŸš€ ìµœì¢… ëª¨ë¸ í›ˆë ¨ (ì—í­: 4, ë°°ì¹˜: 16)\")\n",
    "\n",
    "# 1. fit í•¨ìˆ˜ì—ì„œëŠ” ì €ì¥ ê´€ë ¨ ì˜µì…˜ì„ ì œê±°í•©ë‹ˆë‹¤.\n",
    "cross_encoder_model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    epochs=4,\n",
    "    warmup_steps=warmup_steps,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# 2. í•™ìŠµì´ ì™„ë£Œëœ í›„, .save() ë©”ì„œë“œë¥¼ ëª…ì‹œì ìœ¼ë¡œ í˜¸ì¶œí•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "print(f\"ğŸ’¾ ëª¨ë¸ì„ {output_model_path} ê²½ë¡œì— ì €ì¥ ì¤‘...\")\n",
    "cross_encoder_model.save(output_model_path)\n",
    "print(\"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824e1894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”® Cross-Encoderë¥¼ ì‚¬ìš©í•˜ì—¬ semantic score ì˜ˆì¸¡ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ìš© ë°ì´í„° ë³€í™˜: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2029/2029 [00:00<00:00, 117264.59it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad0b2bb907245f5b2006cffd764a7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Semantic score ('ce_score')ê°€ íŠ¹ì§•ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>rule</th>\n",
       "      <th>ce_score</th>\n",
       "      <th>rule_violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Banks don't want you to know this! Click here ...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>0.073306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SD Stream [ ENG Link 1] (http://www.sportsstre...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>0.030508</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lol. Try appealing the ban and say you won't d...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>0.956159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she will come your home open her legs with  an...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>0.968073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>0.966402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  \\\n",
       "0  Banks don't want you to know this! Click here ...   \n",
       "1  SD Stream [ ENG Link 1] (http://www.sportsstre...   \n",
       "2  Lol. Try appealing the ban and say you won't d...   \n",
       "3  she will come your home open her legs with  an...   \n",
       "4  code free tyrande --->>> [Imgur](http://i.imgu...   \n",
       "\n",
       "                                                rule  ce_score  rule_violation  \n",
       "0  No Advertising: Spam, referral links, unsolici...  0.073306               0  \n",
       "1  No Advertising: Spam, referral links, unsolici...  0.030508               0  \n",
       "2  No legal advice: Do not offer or request legal...  0.956159               1  \n",
       "3  No Advertising: Spam, referral links, unsolici...  0.968073               1  \n",
       "4  No Advertising: Spam, referral links, unsolici...  0.966402               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# âœ¨ NEW: =======================================================\n",
    "# ğŸ¤– 2ë‹¨ê³„ ì¤€ë¹„: Cross-Encoderë¡œ Semantic Feature ìƒì„±\n",
    "# ==========================================================\n",
    "print(\"ğŸ”® Cross-Encoderë¥¼ ì‚¬ìš©í•˜ì—¬ semantic score ì˜ˆì¸¡ ì¤‘...\")\n",
    "\n",
    "# í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ì…ë ¥ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "predict_examples = []\n",
    "for i in tqdm(range(len(ce_inputs)), desc=\"ì˜ˆì¸¡ìš© ë°ì´í„° ë³€í™˜\"):\n",
    "    ce_input = ce_inputs[i]\n",
    "    if '[ëŒ“ê¸€]' in ce_input:\n",
    "        rule_part, comment_part = ce_input.split('[ëŒ“ê¸€]', 1)\n",
    "    else:\n",
    "        rule_part, comment_part = ce_input, \"\"\n",
    "    predict_examples.append([rule_part.strip(), comment_part.strip()])\n",
    "\n",
    "# ì˜ˆì¸¡ ìˆ˜í–‰ (raw logit scores)\n",
    "ce_predictions = cross_encoder_model.predict(predict_examples, show_progress_bar=True)\n",
    "\n",
    "# ì˜ˆì¸¡ ì ìˆ˜ë¥¼ DataFrameì˜ ìƒˆë¡œìš´ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€\n",
    "train_df_featured['ce_score'] = ce_predictions\n",
    "print(\"âœ… Semantic score ('ce_score')ê°€ íŠ¹ì§•ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "display(train_df_featured[['body', 'rule', 'ce_score', 'rule_violation']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c89ded25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ LGBM ëª¨ë¸ì„ ìœ„í•œ íŠ¹ì§• ìŠ¤ì¼€ì¼ë§ ë° ì¸ì½”ë”© ì¤‘...\n",
      "ğŸ”¢ 10ê°œì˜ ìˆ˜ì¹˜ íŠ¹ì§• ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ.\n",
      "ğŸ“‹ 1ê°œì˜ ë²”ì£¼í˜• íŠ¹ì§• ì›-í•« ì¸ì½”ë”© ì™„ë£Œ.\n",
      "âœ… LGBM í›ˆë ¨ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ. ìµœì¢… í˜•íƒœ: (2029, 110)\n"
     ]
    }
   ],
   "source": [
    "# âœ¨ NEW: =======================================================\n",
    "# ğŸ› ï¸ 2ë‹¨ê³„ ì¤€ë¹„: LGBMì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„\n",
    "# ==========================================================\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "print(\"ğŸ”§ LGBM ëª¨ë¸ì„ ìœ„í•œ íŠ¹ì§• ìŠ¤ì¼€ì¼ë§ ë° ì¸ì½”ë”© ì¤‘...\")\n",
    "\n",
    "# 1. ìˆ˜ì¹˜ íŠ¹ì§• (Numerical Features)\n",
    "numerical_cols = [\n",
    "    'body_len', 'rule_len', 'body_words', 'url_cnt', 'exc_cnt', 'q_cnt',\n",
    "    'upper_rt', 'rep_run', 'rule_body_jaccard', \n",
    "    'ce_score' # Cross-Encoder ì˜ˆì¸¡ ì ìˆ˜ í¬í•¨!\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "numerical_features = scaler.fit_transform(train_df_featured[numerical_cols])\n",
    "print(f\"ğŸ”¢ {len(numerical_cols)}ê°œì˜ ìˆ˜ì¹˜ íŠ¹ì§• ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ.\")\n",
    "\n",
    "# 2. ë²”ì£¼í˜• íŠ¹ì§• (Categorical Features) - EDA ì¸ì‚¬ì´íŠ¸ ë°˜ì˜!\n",
    "categorical_cols = ['subreddit']\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "categorical_features = onehot_encoder.fit_transform(train_df_featured[categorical_cols])\n",
    "print(f\"ğŸ“‹ {len(categorical_cols)}ê°œì˜ ë²”ì£¼í˜• íŠ¹ì§• ì›-í•« ì¸ì½”ë”© ì™„ë£Œ.\")\n",
    "\n",
    "# 3. ëª¨ë“  íŠ¹ì§• ê²°í•©\n",
    "X_lgbm = hstack([numerical_features, categorical_features])\n",
    "y_lgbm = train_df_featured['rule_violation'].values\n",
    "\n",
    "print(f\"âœ… LGBM í›ˆë ¨ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ. ìµœì¢… í˜•íƒœ: {X_lgbm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c780c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ LightGBM ëª¨ë¸ í›ˆë ¨ ì‹œì‘...\n",
      "[LightGBM] [Info] Number of positive: 1031, number of negative: 998\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1030\n",
      "[LightGBM] [Info] Number of data points in the train set: 2029, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508132 -> initscore=0.032531\n",
      "[LightGBM] [Info] Start training from score 0.032531\n",
      "âœ… LightGBM ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# âœ¨ NEW: =======================================================\n",
    "# ğŸ—ï¸ 2ë‹¨ê³„: LightGBM ëª¨ë¸ í›ˆë ¨\n",
    "# ==========================================================\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(\"ğŸš€ LightGBM ëª¨ë¸ í›ˆë ¨ ì‹œì‘...\")\n",
    "\n",
    "lgbm_model = lgb.LGBMClassifier(\n",
    "    objective='binary',\n",
    "    metric='auc',\n",
    "    n_estimators=1000, # ì¡°ê¸° ì¢…ë£Œë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ë„‰ë„‰í•˜ê²Œ ì„¤ì •\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8\n",
    ")\n",
    "\n",
    "# LGBM í›ˆë ¨\n",
    "lgbm_model.fit(X_lgbm, y_lgbm, \n",
    "             eval_set=[(X_lgbm, y_lgbm)],\n",
    "             eval_metric='auc',\n",
    "             callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "\n",
    "print(\"âœ… LightGBM ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a93bb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ ëª¨ë¸ ë° ì „ì²˜ë¦¬ ê°ì²´ ì €ì¥ ì¤‘...\n",
      "âœ… Cross-Encoder ëª¨ë¸ ì €ì¥ ì™„ë£Œ: /workspace/Agile-Community-Rules-Classification/model_output/final_cross_encoder_model\n",
      "âœ… LGBM ëª¨ë¸ ì €ì¥ ì™„ë£Œ: ./model_output/lgbm_model.pkl\n",
      "âœ… Scaler ì €ì¥ ì™„ë£Œ: ./model_output/scaler.pkl\n",
      "âœ… OneHotEncoder ì €ì¥ ì™„ë£Œ: ./model_output/onehot_encoder.pkl\n",
      "âœ… ìˆ˜ì¹˜ íŠ¹ì§• ì»¬ëŸ¼ëª… ì €ì¥ ì™„ë£Œ: ./model_output/numerical_cols.pkl\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# ğŸ’¾ ìµœì¢… ëª¨ë¸ ë° ì „ì²˜ë¦¬ ê°ì²´ ì €ì¥\n",
    "# ==========================================================\n",
    "print(\"ğŸ’¾ ëª¨ë¸ ë° ì „ì²˜ë¦¬ ê°ì²´ ì €ì¥ ì¤‘...\")\n",
    "output_dir = './model_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 1. Cross-Encoder ëª¨ë¸ì€ ì´ë¯¸ output_pathì— ì €ì¥ë¨\n",
    "print(f\"âœ… Cross-Encoder ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {os.path.abspath(output_model_path)}\")\n",
    "\n",
    "# âœ¨ NEW: 2. LGBM ëª¨ë¸ ì €ì¥\n",
    "joblib.dump(lgbm_model, os.path.join(output_dir, 'lgbm_model.pkl'))\n",
    "print(f\"âœ… LGBM ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {os.path.join(output_dir, 'lgbm_model.pkl')}\")\n",
    "\n",
    "# 3. Scaler ì €ì¥\n",
    "joblib.dump(scaler, os.path.join(output_dir, 'scaler.pkl'))\n",
    "print(f\"âœ… Scaler ì €ì¥ ì™„ë£Œ: {os.path.join(output_dir, 'scaler.pkl')}\")\n",
    "\n",
    "# âœ¨ NEW: 4. OneHotEncoder ì €ì¥\n",
    "joblib.dump(onehot_encoder, os.path.join(output_dir, 'onehot_encoder.pkl'))\n",
    "print(f\"âœ… OneHotEncoder ì €ì¥ ì™„ë£Œ: {os.path.join(output_dir, 'onehot_encoder.pkl')}\")\n",
    "\n",
    "# 5. ìˆ˜ì¹˜ íŠ¹ì§• ì»¬ëŸ¼ëª… ì €ì¥\n",
    "with open(os.path.join(output_dir, 'numerical_cols.pkl'), 'wb') as f:\n",
    "    pickle.dump(numerical_cols, f)\n",
    "print(f\"âœ… ìˆ˜ì¹˜ íŠ¹ì§• ì»¬ëŸ¼ëª… ì €ì¥ ì™„ë£Œ: {os.path.join(output_dir, 'numerical_cols.pkl')}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

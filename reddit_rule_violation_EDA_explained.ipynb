{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b601c1a0",
   "metadata": {},
   "source": [
    "\n",
    "# 🧭 Reddit Rule Violation: Research‑Backed EDA → Baseline Modeling Notebook\n",
    "\n",
    "이 노트북은 **Kaggle \"Jigsaw - Agile Community Rules Classification\"** 과 유사한 과제 맥락에서, 제공된 `train.csv`(comment, rule 쌍) 기반으로 **연구 근거를 반영한 EDA**를 수행하고, **인사이트 → 특징 설계 → 베이스라인 학습**까지 **흐름 있게** 진행합니다.\n",
    "\n",
    "## 참고/배경 (연구 & 레퍼런스)\n",
    "- **Rule-based moderation with LLMs**: LLM이 서브레딧 규칙을 프롬프트로 받아 규칙 위반 여부를 추론하는 연구. 커뮤니티별 성능 편차가 존재하며 **룰 텍스트와 댓글 텍스트의 상호작용(쌍 입력)**이 핵심임.  \n",
    "  - Kumar, AbuHashem, Durumeric (2023/2024): *Watch Your Language: Investigating Content Moderation with LLMs*. (ICWSM 2024)  \n",
    "- **레딧 모더레이션 데이터셋/규범 연구**: 레딧에서 삭제/제거된 수백만 코멘트 분석, 커뮤니티 규범(macro/micro) 위반 탐지. **스팸/광고, 인신공격, 정치/규칙 위반** 등 이질적 규범 존재.  \n",
    "  - Chandrasekharan & Gilbert (2018/2019): *Norm Violations*, *Hybrid Approaches*, *Crossmod* 등.\n",
    "- **실무적 베이스라인**: 텍스트 분류에서 **TF‑IDF + 로지스틱 회귀**가 낮은 연산비로 강한 성능·AUC 확보. Toxic/abuse 탐지 벤치마크에서도 일관되게 강함.\n",
    "- **스팸/광고 신호**: URL 수, 도메인, 반복문자, 과도한 대문자/구두점, 길이, 이모지 비율 등 **스타일 특징**이 유용함.\n",
    "\n",
    "> 본 노트북은 위 근거를 반영해 **(1) 데이터 품질/분포 점검 → (2) 규칙/커뮤니티/텍스트 특성 분석 → (3) 룰-본문 쌍 상호작용 특징**(유사도, TF‑IDF 쌍 인코딩 등) → (4) **베이스라인 모델(AUC 검증)** → (5) 개선 로드맵 순으로 구성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e7ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re, math, string, unicodedata, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "DATA_PATH = '/mnt/data/train.csv' if os.path.exists('/mnt/data/train.csv') else 'train.csv'\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c6dbeb",
   "metadata": {},
   "source": [
    "## 1) 데이터 개요 / 무결성 점검"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664e1bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.sample(5, random_state=42))\n",
    "display(df.describe(include='all'))\n",
    "print(\"\\nNull counts:\\n\", df.isnull().sum())\n",
    "print(\"\\nDtypes:\\n\", df.dtypes)\n",
    "dup_pairs = df.duplicated(subset=['body','rule']).sum()\n",
    "print(f\"Duplicated (body, rule) pairs: {dup_pairs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8732a279",
   "metadata": {},
   "source": [
    "## 2) 타깃 분포 (`rule_violation`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ad205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = 'rule_violation'\n",
    "vc = df[target].value_counts().sort_index()\n",
    "print(vc)\n",
    "print(\"\\nClass ratio:\", (vc / vc.sum()).to_dict())\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.bar(vc.index.astype(str), vc.values)\n",
    "plt.title('Rule Violation Distribution')\n",
    "plt.xlabel('rule_violation')\n",
    "plt.ylabel('count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6a53d",
   "metadata": {},
   "source": [
    "## 3) Subreddit 분포 및 규칙 위반율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5fd157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sub_vc = df['subreddit'].value_counts()\n",
    "print(\"Unique subreddits:\", df['subreddit'].nunique())\n",
    "display(sub_vc.head(20))\n",
    "\n",
    "sub_stats = (df.groupby('subreddit')[target]\n",
    "               .agg(['mean','count'])\n",
    "               .rename(columns={'mean':'violation_rate','count':'n'})\n",
    "               .sort_values('n', ascending=False))\n",
    "display(sub_stats.head(20))\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "top_counts = sub_vc.head(20)\n",
    "plt.barh(range(len(top_counts)), top_counts.values)\n",
    "plt.yticks(range(len(top_counts)), top_counts.index)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Top 20 Subreddits (by count)')\n",
    "plt.xlabel('count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "top_subs = sub_stats.head(20)\n",
    "plt.barh(range(len(top_subs)), top_subs['violation_rate'].values)\n",
    "plt.yticks(range(len(top_subs)), top_subs.index)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Top 20 Subreddits - Violation Rate')\n",
    "plt.xlabel('violation_rate')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d807f7ba",
   "metadata": {},
   "source": [
    "## 4) Rule(규칙) 분포 & 위반율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a8ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rule_vc = df['rule'].value_counts()\n",
    "print(\"Unique rules:\", df['rule'].nunique())\n",
    "display(rule_vc.head(15))\n",
    "\n",
    "rule_stats = (df.groupby('rule')[target]\n",
    "                .agg(['mean','count'])\n",
    "                .rename(columns={'mean':'violation_rate','count':'n'})\n",
    "                .sort_values('n', ascending=False))\n",
    "display(rule_stats.head(20))\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "top_rules = rule_vc.head(15)\n",
    "plt.barh(range(len(top_rules)), top_rules.values)\n",
    "plt.yticks(range(len(top_rules)), top_rules.index)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Top 15 Rules (by count)')\n",
    "plt.xlabel('count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "top_rules_stats = rule_stats.head(15)\n",
    "plt.barh(range(len(top_rules_stats)), top_rules_stats['violation_rate'].values)\n",
    "plt.yticks(range(len(top_rules_stats)), top_rules_stats.index)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title('Top 15 Rules - Violation Rate')\n",
    "plt.xlabel('violation_rate')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6556a546",
   "metadata": {},
   "source": [
    "## 5) 본문 길이/기초 통계 (스팸·규범 위반 관련 신호)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d89dd",
   "metadata": {},
   "source": [
    "### 🔎 Lexicon 기반 특징이란?\n",
    "Lexicon은 특정 주제(예: 욕설, 광고)와 관련된 **단어 사전**을 의미합니다.  \n",
    "EDA에서 `url_cnt`, `upper_rt`, `exc_cnt` 같은 컬럼은 단어 사전이나 스타일 규칙에 기반해 생성된 특징입니다.  \n",
    "즉, **본문 자체 의미보다 글쓰기 패턴(스타일)** 을 이용해 규칙 위반을 탐지하는 보조 신호입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc14494",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_urls(text):\n",
    "    return len(re.findall(r'https?://\\S+|www\\.\\S+', str(text)))\n",
    "\n",
    "def count_exclaims(text):\n",
    "    return str(text).count('!')\n",
    "\n",
    "def count_questions(text):\n",
    "    return str(text).count('?')\n",
    "\n",
    "def upper_ratio(text):\n",
    "    s = str(text)\n",
    "    letters = [c for c in s if c.isalpha()]\n",
    "    if not letters:\n",
    "        return 0.0\n",
    "    upp = sum(1 for c in letters if c.isupper())\n",
    "    return upp / len(letters)\n",
    "\n",
    "def repeat_char_max(text):\n",
    "    longest = 1\n",
    "    last = ''\n",
    "    cur = 0\n",
    "    for ch in str(text):\n",
    "        if ch == last:\n",
    "            cur += 1\n",
    "        else:\n",
    "            longest = max(longest, cur)\n",
    "            cur = 1\n",
    "            last = ch\n",
    "    longest = max(longest, cur)\n",
    "    return longest\n",
    "\n",
    "def emoji_ratio(text):\n",
    "    s = str(text)\n",
    "    total = len(s) if len(s)>0 else 1\n",
    "    emojis = sum(1 for ch in s if ch in emoji_set)\n",
    "    return emojis / total\n",
    "\n",
    "emoji_set = set(list(\"😀😃😄😁😆😅😂🤣🥲😊🙂🙃😉😍😘😗😙😚😋😛😝😜🤪🤨🧐🤓😎🤩🥳😏😒😞😔😟😕🙁☹️😣😖😫😩😤😠😡🤬\"))\n",
    "\n",
    "df['body_len'] = df['body'].astype(str).str.len()\n",
    "df['url_cnt'] = df['body'].apply(count_urls)\n",
    "df['exc_cnt'] = df['body'].apply(count_exclaims)\n",
    "df['q_cnt']   = df['body'].apply(count_questions)\n",
    "df['upper_rt'] = df['body'].apply(upper_ratio)\n",
    "df['rep_run']  = df['body'].apply(repeat_char_max)\n",
    "df['emoji_rt'] = df['body'].apply(emoji_ratio)\n",
    "\n",
    "display(df[['body_len','url_cnt','exc_cnt','q_cnt','upper_rt','rep_run','emoji_rt', 'rule_violation']].describe())\n",
    "\n",
    "fig, axes = plt.subplots(2,3, figsize=(12,7)); axes = axes.ravel()\n",
    "axes[0].hist(df['body_len'], bins=50); axes[0].set_title('body_len')\n",
    "axes[1].hist(df['url_cnt'], bins=20);  axes[1].set_title('url_cnt')\n",
    "axes[2].hist(df['upper_rt'], bins=30); axes[2].set_title('upper_rt')\n",
    "axes[3].hist(df['exc_cnt'], bins=20);  axes[3].set_title('exc_cnt')\n",
    "axes[4].hist(df['q_cnt'], bins=20);    axes[4].set_title('q_cnt')\n",
    "axes[5].hist(df['rep_run'], bins=20);  axes[5].set_title('rep_run')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "for m in ['body_len','url_cnt','upper_rt','exc_cnt','q_cnt','rep_run','emoji_rt']:\n",
    "    plt.figure(figsize=(4,3))\n",
    "    data0 = df.loc[df[target]==0, m].values\n",
    "    data1 = df.loc[df[target]==1, m].values\n",
    "    plt.boxplot([data0, data1], labels=['non-viol','viol'])\n",
    "    plt.title(m)\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "corr = df[['body_len','url_cnt','upper_rt','exc_cnt','q_cnt','rep_run','emoji_rt', target]].corr(numeric_only=True)[target].sort_values(ascending=False)\n",
    "print(\"Correlation with target (pearson):\\n\", corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fd10af",
   "metadata": {},
   "source": [
    "## 6) 경량 Lexicon 기반 신호 (욕설/광고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc05a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "profanity = {'idiot','moron','stupid','dumb','retard','asshole','bastard'}\n",
    "ad_words  = {'free','win','offer','discount','promo','sale','subscribe','click','visit','buy','deal','coupon','%off'}\n",
    "\n",
    "def contains_any(text, vocab):\n",
    "    s = str(text).lower()\n",
    "    return int(any(tok in s for tok in vocab))\n",
    "\n",
    "df['has_profanity'] = df['body'].apply(lambda x: contains_any(x, profanity))\n",
    "df['has_adword']    = df['body'].apply(lambda x: contains_any(x, ad_words))\n",
    "\n",
    "print(df[['has_profanity','has_adword', target]].groupby(['has_profanity','has_adword']).agg(['mean','count']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dce80d4",
   "metadata": {},
   "source": [
    "## 7) 규칙 텍스트 vs 본문 상호작용 (유사도 특징)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1732a905",
   "metadata": {},
   "source": [
    "### 📐 Jaccard 유사도\n",
    "Jaccard 유사도는 **두 집합의 교집합 비율**로 정의됩니다.  \n",
    "➡ 규칙 텍스트와 댓글 텍스트를 단어 집합으로 바꿔, 겹치는 단어 비율을 측정합니다.  \n",
    "\n",
    "- 값 범위: 0 (겹침 없음) ~ 1 (완전히 동일)\n",
    "- 규칙 위반 댓글일수록 규칙 문구와 단어가 겹칠 확률이 높아, Jaccard 값이 높아집니다.\n",
    "\n",
    "👉 따라서 규칙 위반 탐지에서 **규칙-본문 상호작용**을 반영하는 중요한 신호입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1da7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def jaccard(a, b):\n",
    "    sa, sb = set(a.split()), set(b.split())\n",
    "    u = len(sa|sb); i = len(sa&sb)\n",
    "    return i / u if u else 0.0\n",
    "\n",
    "df['rule_body_jaccard'] = [jaccard(r, b) for r,b in zip(df['rule'].astype(str), df['body'].astype(str))]\n",
    "print(\"rule_body_jaccard head:\\n\", df['rule_body_jaccard'].head())\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.hist(df['rule_body_jaccard'], bins=30)\n",
    "plt.title('Jaccard(rule, body)')\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.boxplot([df.loc[df[target]==0, 'rule_body_jaccard'],\n",
    "             df.loc[df[target]==1, 'rule_body_jaccard']], labels=['non-viol','viol'])\n",
    "plt.title('Jaccard vs target')\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ec573b",
   "metadata": {},
   "source": [
    "## 8) 제공된 예시 텍스트(positive/negative example)와의 유사도/누설 점검"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4327a0",
   "metadata": {},
   "source": [
    "### 🚨 데이터 누설(Leakage) 점검\n",
    "규칙 예시 텍스트(`positive_example_1` 등)가 댓글 본문에 포함되는 경우,  \n",
    "모델은 '예시 문구=정답'이라는 편법을 학습해버릴 수 있습니다.  \n",
    "따라서 `body_contains_xxx` 컬럼을 만들어 실제 포함 여부를 확인하고, 타깃과의 상관을 검토합니다.  \n",
    "이는 **데이터셋 설계상 누설 여부를 검증하는 핵심 절차**입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ae897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ex_cols = ['positive_example_1','positive_example_2','negative_example_1','negative_example_2']\n",
    "for col in ex_cols:\n",
    "    df[f'body_contains_{col}'] = df.apply(lambda r: int(str(r[col])[:120].lower() in str(r['body']).lower()), axis=1)\n",
    "    print(col, df[f'body_contains_{col}'].sum())\n",
    "\n",
    "leak_cols = [c for c in df.columns if c.startswith('body_contains_')]\n",
    "display(df[leak_cols + [target]].groupby(leak_cols)[target].agg(['mean','count']).sort_values('count', ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f55c6ae",
   "metadata": {},
   "source": [
    "## 9) 모델링 입력 구성 (텍스트 + 스타일 + 상호작용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de505180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['rule_sep_body'] = df['rule'].astype(str) + ' [SEP] ' + df['body'].astype(str)\n",
    "num_cols = ['body_len','url_cnt','exc_cnt','q_cnt','upper_rt','rep_run','emoji_rt','has_profanity','has_adword','rule_body_jaccard']\n",
    "X_text = df['rule_sep_body']; X_num = df[num_cols]\n",
    "y = df[target].astype(int)\n",
    "display(X_num.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3e8909",
   "metadata": {},
   "source": [
    "## 10) 베이스라인: TF‑IDF(word+char) + 로지스틱 회귀 (Stratified 5‑Fold AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3489e80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "tf_word = TfidfVectorizer(strip_accents='unicode', lowercase=True, ngram_range=(1,2), min_df=2, max_features=40000)\n",
    "tf_char = TfidfVectorizer(analyzer='char', ngram_range=(3,5), min_df=2, max_features=60000)\n",
    "scaler  = StandardScaler(with_mean=False)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_pred = np.zeros(len(df), dtype=float)\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (tr, va) in enumerate(skf.split(X_text, y), 1):\n",
    "    Xw_tr = tf_word.fit_transform(X_text.iloc[tr]); Xw_va = tf_word.transform(X_text.iloc[va])\n",
    "    Xc_tr = tf_char.fit_transform(X_text.iloc[tr]); Xc_va = tf_char.transform(X_text.iloc[va])\n",
    "    Xn_tr = scaler.fit_transform(X_num.iloc[tr]);   Xn_va = scaler.transform(X_num.iloc[va])\n",
    "    X_tr = hstack([Xw_tr, Xc_tr, Xn_tr], format='csr')\n",
    "    X_va = hstack([Xw_va, Xc_va, Xn_va], format='csr')\n",
    "    clf = LogisticRegression(solver='saga', max_iter=3000, n_jobs=-1, class_weight='balanced', C=2.0, penalty='l2')\n",
    "    clf.fit(X_tr, y.iloc[tr])\n",
    "    oof_pred[va] = clf.predict_proba(X_va)[:,1]\n",
    "    auc = roc_auc_score(y.iloc[va], oof_pred[va])\n",
    "    fold_scores.append(auc)\n",
    "    print(f\"[Fold {fold}] AUC = {auc:.4f}\")\n",
    "print(\"\\nCV AUC:\", np.mean(fold_scores).round(4), \"+/-\", np.std(fold_scores).round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb59c8",
   "metadata": {},
   "source": [
    "## 11) 단어 중요도 살펴보기 (참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39704401",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    word_feats = np.array(tf_word.get_feature_names_out())\n",
    "    coefs = clf.coef_[0][:len(word_feats)]\n",
    "    idx_top = np.argsort(-coefs)[:30]\n",
    "    idx_bot = np.argsort(coefs)[:30]\n",
    "    print(\"Top +coef tokens (push to violation):\")\n",
    "    print(list(zip(word_feats[idx_top], coefs[idx_top])))\n",
    "    print(\"\\nTop -coef tokens (push to non-violation):\")\n",
    "    print(list(zip(word_feats[idx_bot], coefs[idx_bot])))\n",
    "except Exception as e:\n",
    "    print(\"Feature importance preview skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c0d88b",
   "metadata": {},
   "source": [
    "\n",
    "## 12) 주요 인사이트 요약 → 액션 아이템\n",
    "\n",
    "- **서브레딧·규칙별 분포 차이**: 데이터는 커뮤니티/룰에 따라 **표본 수와 위반율**이 상이합니다. **Stratified split** 및 **커뮤니티/룰 분포 보정**이 필요합니다.\n",
    "- **스팸/광고 신호**: URL 수, 반복문자, 대문자 비율, 감탄/물음표 과다 등 **스타일 특징**이 위반과 상관(상세 수치 위 셀 참고).\n",
    "- **룰-본문 상호작용**: `rule` 텍스트와 `body`간 **토큰 공유율(Jaccard)** 또는 **합쳐서 벡터화(rule [SEP] body)**가 유효한 신호로 보입니다.\n",
    "- **예시 텍스트 누설 점검**: 댓글 본문이 예시 문자열 일부를 포함하는 사례가 있는지 반드시 확인(상기 결과 참고). 존재 시, 해당 특징 사용은 금지하거나 교정 필요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac70c3d4",
   "metadata": {},
   "source": [
    "## 13) 전체 재학습 & 제출 함수 (test.csv 가정)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1a6f6",
   "metadata": {},
   "source": [
    "### 📐 Jaccard 유사도\n",
    "Jaccard 유사도는 **두 집합의 교집합 비율**로 정의됩니다.  \n",
    "➡ 규칙 텍스트와 댓글 텍스트를 단어 집합으로 바꿔, 겹치는 단어 비율을 측정합니다.  \n",
    "\n",
    "- 값 범위: 0 (겹침 없음) ~ 1 (완전히 동일)\n",
    "- 규칙 위반 댓글일수록 규칙 문구와 단어가 겹칠 확률이 높아, Jaccard 값이 높아집니다.\n",
    "\n",
    "👉 따라서 규칙 위반 탐지에서 **규칙-본문 상호작용**을 반영하는 중요한 신호입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc408f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def jaccard(a, b):\n",
    "    sa, sb = set(a.split()), set(b.split())\n",
    "    u = len(sa|sb); i = len(sa&sb)\n",
    "    return i / u if u else 0.0\n",
    "\n",
    "def fit_full_and_predict(train_df, test_df):\n",
    "    X_text_tr = train_df['rule'].astype(str) + ' [SEP] ' + train_df['body'].astype(str)\n",
    "    X_text_te = test_df['rule'].astype(str) + ' [SEP] ' + test_df['body'].astype(str)\n",
    "    y_tr = train_df['rule_violation'].astype(int)\n",
    "\n",
    "    # 파생 생성 for test\n",
    "    def enrich(df_):\n",
    "        df_ = df_.copy()\n",
    "        df_['body_len'] = df_['body'].astype(str).str.len()\n",
    "        df_['url_cnt'] = df_['body'].apply(lambda t: len(re.findall(r'https?://\\S+|www\\.\\S+', str(t))))\n",
    "        df_['exc_cnt'] = df_['body'].apply(lambda t: str(t).count('!'))\n",
    "        df_['q_cnt']   = df_['body'].apply(lambda t: str(t).count('?'))\n",
    "        def upper_ratio(text):\n",
    "            s = str(text)\n",
    "            letters = [c for c in s if c.isalpha()]\n",
    "            if not letters:\n",
    "                return 0.0\n",
    "            upp = sum(1 for c in letters if c.isupper())\n",
    "            return upp / len(letters)\n",
    "        df_['upper_rt'] = df_['body'].apply(upper_ratio)\n",
    "        def repeat_char_max(text):\n",
    "            longest = 1; last=''; cur=0\n",
    "            for ch in str(text):\n",
    "                if ch == last: cur += 1\n",
    "                else: longest = max(longest, cur); cur=1; last=ch\n",
    "            longest = max(longest, cur)\n",
    "            return longest\n",
    "        df_['rep_run']  = df_['body'].apply(repeat_char_max)\n",
    "        emoji_set = set(list(\"😀😃😄😁😆😅😂🤣🥲😊🙂🙃😉😍😘😗😙😚😋😛😝😜🤪🤨🧐🤓😎🤩🥳😏😒😞😔😟😕🙁☹️😣😖😫😩😤😠😡🤬\"))\n",
    "        df_['emoji_rt'] = df_['body'].apply(lambda s: (sum(1 for ch in str(s) if ch in emoji_set) / (len(str(s)) if len(str(s))>0 else 1)))\n",
    "        profanity = {'idiot','moron','stupid','dumb','retard','asshole','bastard'}\n",
    "        ad_words  = {'free','win','offer','discount','promo','sale','subscribe','click','visit','buy','deal','coupon','%off'}\n",
    "        df_['has_profanity'] = df_['body'].apply(lambda x: int(any(tok in str(x).lower() for tok in profanity)))\n",
    "        df_['has_adword']    = df_['body'].apply(lambda x: int(any(tok in str(x).lower() for tok in ad_words)))\n",
    "        df_['rule_body_jaccard'] = [jaccard(r, b) for r,b in zip(df_['rule'].astype(str), df_['body'].astype(str))]\n",
    "        return df_\n",
    "\n",
    "    train_df = enrich(train_df); test_df = enrich(test_df)\n",
    "\n",
    "    num_cols = ['body_len','url_cnt','exc_cnt','q_cnt','upper_rt','rep_run','emoji_rt','has_profanity','has_adword','rule_body_jaccard']\n",
    "    X_num_tr = train_df[num_cols]; X_num_te = test_df[num_cols]\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from scipy.sparse import hstack\n",
    "\n",
    "    tf_word = TfidfVectorizer(strip_accents='unicode', lowercase=True, ngram_range=(1,2), min_df=2, max_features=40000)\n",
    "    tf_char = TfidfVectorizer(analyzer='char', ngram_range=(3,5), min_df=2, max_features=60000)\n",
    "    scaler  = StandardScaler(with_mean=False)\n",
    "\n",
    "    Xw_tr = tf_word.fit_transform(X_text_tr); Xw_te = tf_word.transform(X_text_te)\n",
    "    Xc_tr = tf_char.fit_transform(X_text_tr); Xc_te = tf_char.transform(X_text_te)\n",
    "    Xn_tr = scaler.fit_transform(X_num_tr);   Xn_te = scaler.transform(X_num_te)\n",
    "\n",
    "    X_tr = hstack([Xw_tr, Xc_tr, Xn_tr], format='csr')\n",
    "    X_te = hstack([Xw_te, Xc_te, Xn_te], format='csr')\n",
    "\n",
    "    clf = LogisticRegression(solver='saga', max_iter=3000, n_jobs=-1, class_weight='balanced', C=2.0, penalty='l2')\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    proba = clf.predict_proba(X_te)[:,1]\n",
    "    return proba\n",
    "\n",
    "def make_submission(test_csv_path, out_path='submission.csv'):\n",
    "    test_df = pd.read_csv(test_csv_path)\n",
    "    probs = fit_full_and_predict(df.copy(), test_df.copy())\n",
    "    sub = pd.DataFrame({'row_id': test_df['row_id'], 'rule_violation': probs})\n",
    "    sub.to_csv(out_path, index=False)\n",
    "    print(\"Saved:\", out_path)\n",
    "    return sub\n",
    "\n",
    "print(\"Ready: call make_submission('test.csv') when test is available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b1be34",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_submission('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b494f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

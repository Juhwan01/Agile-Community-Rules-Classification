{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1781db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📚 필수 라이브러리 설치 및 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "print(f\"GPU 사용 가능: {torch.cuda.is_available()}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"사용 디바이스: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 📊 데이터 로드 및 기본 정보 확인\n",
    "# 로컬 경로에서 학습 데이터를 불러옵니다.\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "print(f\"🔍 데이터 형태: {train_df.shape}\")\n",
    "print(f\"🎯 타겟 분포: {train_df['rule_violation'].value_counts().to_dict()}\")\n",
    "print(\"\\n📋 데이터 샘플:\")\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66819f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 🛠️ 특징 엔지니어링 함수 정의\n",
    "def count_urls(text):\n",
    "    \"\"\"URL 개수 세기\"\"\"\n",
    "    return len(re.findall(r'https?://\\S+|www\\.\\S+', str(text)))\n",
    "\n",
    "def count_exclaims(text):\n",
    "    \"\"\"감탄표 개수 세기\"\"\"\n",
    "    return str(text).count('!')\n",
    "\n",
    "def count_questions(text):\n",
    "    \"\"\"물음표 개수 세기\"\"\"\n",
    "    return str(text).count('?')\n",
    "\n",
    "def upper_ratio(text):\n",
    "    \"\"\"대문자 비율 계산\"\"\"\n",
    "    s = str(text)\n",
    "    letters = [c for c in s if c.isalpha()]\n",
    "    if not letters:\n",
    "        return 0.0\n",
    "    upp = sum(1 for c in letters if c.isupper())\n",
    "    return upp / len(letters)\n",
    "\n",
    "def repeat_char_max(text):\n",
    "    \"\"\"연속된 문자의 최대 길이\"\"\"\n",
    "    longest = 1\n",
    "    last = ''\n",
    "    cur = 0\n",
    "    for ch in str(text):\n",
    "        if ch == last:\n",
    "            cur += 1\n",
    "        else:\n",
    "            longest = max(longest, cur)\n",
    "            cur = 1\n",
    "            last = ch\n",
    "    longest = max(longest, cur)\n",
    "    return longest\n",
    "\n",
    "def jaccard_similarity(text1, text2):\n",
    "    \"\"\"자카드 유사도 계산\"\"\"\n",
    "    set1 = set(str(text1).lower().split())\n",
    "    set2 = set(str(text2).lower().split())\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "# ==========================================================\n",
    "# 🔧 특징 생성 함수\n",
    "def create_features(df):\n",
    "    \"\"\"EDA에서 발견한 유용한 특징들을 생성\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(\"📏 기본 텍스트 특징 생성 중...\")\n",
    "    df['body_len'] = df['body'].astype(str).str.len()\n",
    "    df['rule_len'] = df['rule'].astype(str).str.len()\n",
    "    df['body_words'] = df['body'].astype(str).str.split().str.len()\n",
    "    \n",
    "    print(\"🎨 스타일 특징 생성 중...\")\n",
    "    df['url_cnt'] = df['body'].apply(count_urls)\n",
    "    df['exc_cnt'] = df['body'].apply(count_exclaims)\n",
    "    df['q_cnt'] = df['body'].apply(count_questions)\n",
    "    df['upper_rt'] = df['body'].apply(upper_ratio)\n",
    "    df['rep_run'] = df['body'].apply(repeat_char_max)\n",
    "    \n",
    "    print(\"😊 이모지 및 특수문자 특징 생성 중...\")\n",
    "    emoji_set = set(\"😀😃😄😁😆😅😂🤣🥲😊🙂🙃😉😍😘😗😙😚😋😛😝😜🤪🤨🧐🤓😎🤩🥳😏😒😞😔😟😕🙁☹️😣😖😫😩😤😠😡🤬\")\n",
    "    df['emoji_rt'] = df['body'].apply(\n",
    "        lambda s: sum(1 for ch in str(s) if ch in emoji_set) / max(len(str(s)), 1)\n",
    "    )\n",
    "    \n",
    "    print(\"📚 어휘 기반 특징 생성 중...\")\n",
    "    profanity_words = {'idiot', 'moron', 'stupid', 'dumb', 'retard', 'asshole', \n",
    "                      'bastard', 'fuck', 'shit', 'damn', 'bitch'}\n",
    "    ad_words = {'free', 'win', 'offer', 'discount', 'promo', 'sale', 'subscribe',\n",
    "                'click', 'visit', 'buy', 'deal', 'coupon', 'limited'}\n",
    "    \n",
    "    df['has_profanity'] = df['body'].apply(\n",
    "        lambda x: int(any(word in str(x).lower() for word in profanity_words))\n",
    "    )\n",
    "    df['has_adword'] = df['body'].apply(\n",
    "        lambda x: int(any(word in str(x).lower() for word in ad_words))\n",
    "    )\n",
    "    \n",
    "    print(\"🔗 규칙-댓글 상호작용 특징 생성 중...\")\n",
    "    df['rule_body_jaccard'] = [\n",
    "        jaccard_similarity(rule, body) \n",
    "        for rule, body in zip(df['rule'], df['body'])\n",
    "    ]\n",
    "    \n",
    "    print(\"✅ 특징 생성 완료!\")\n",
    "    return df\n",
    "\n",
    "# ==========================================================\n",
    "# 🤖 Cross-Encoder 입력 준비 함수\n",
    "def prepare_cross_encoder_input(rule, body, positive_ex1=None, positive_ex2=None, \n",
    "                               negative_ex1=None, negative_ex2=None):\n",
    "    \"\"\"Cross-Encoder를 위한 입력 텍스트 준비\"\"\"\n",
    "    rule_text = str(rule).strip()\n",
    "    comment_text = str(body).strip()\n",
    "    \n",
    "    examples_text = \"\"\n",
    "    if pd.notna(positive_ex1) and str(positive_ex1).strip():\n",
    "        examples_text += f\" [긍정예시] {str(positive_ex1).strip()}\"\n",
    "    if pd.notna(negative_ex1) and str(negative_ex1).strip():\n",
    "        examples_text += f\" [부정예시] {str(negative_ex1).strip()}\"\n",
    "    \n",
    "    full_input = f\"[규칙] {rule_text}{examples_text} [댓글] {comment_text}\"\n",
    "    return full_input\n",
    "\n",
    "# ==========================================================\n",
    "# 📊 데이터 전처리 및 특징 생성\n",
    "print(\"🔧 데이터 전처리 시작...\")\n",
    "\n",
    "# 특징 생성 실행\n",
    "train_df = create_features(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb6d6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치 특징 정의\n",
    "numerical_cols = [\n",
    "    'body_len', 'rule_len', 'body_words', 'url_cnt', 'exc_cnt', 'q_cnt',\n",
    "    'upper_rt', 'rep_run', 'emoji_rt', 'has_profanity', 'has_adword', \n",
    "    'rule_body_jaccard'\n",
    "]\n",
    "\n",
    "# 수치 특징 정규화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_features = scaler.fit_transform(train_df[numerical_cols])\n",
    "\n",
    "# Cross-Encoder 입력 데이터 준비\n",
    "print(\"🔄 Cross-Encoder 입력 데이터 준비 중...\")\n",
    "ce_inputs = []\n",
    "labels = []\n",
    "\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"입력 데이터 처리\"):\n",
    "    ce_input = prepare_cross_encoder_input(\n",
    "        row['rule'], \n",
    "        row['body'],\n",
    "        row.get('positive_example_1'),\n",
    "        row.get('positive_example_2'),\n",
    "        row.get('negative_example_1'),\n",
    "        row.get('negative_example_2')\n",
    "    )\n",
    "    ce_inputs.append(ce_input)\n",
    "    labels.append(int(row['rule_violation']))\n",
    "\n",
    "ce_inputs = np.array(ce_inputs)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"✅ {len(ce_inputs)}개의 Cross-Encoder 입력 쌍 준비 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bea179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 🏗️ 최종 모델 훈련 (전체 데이터 사용)\n",
    "from sentence_transformers import CrossEncoder, InputExample\n",
    "\n",
    "print(\"🏗️ 전체 데이터셋으로 최종 모델 훈련 시작!\")\n",
    "\n",
    "# 모델 저장 경로 설정\n",
    "output_model_path = './model_output/final_cross_encoder_model'\n",
    "os.makedirs(os.path.dirname(output_model_path), exist_ok=True) # 저장 폴더 생성\n",
    "\n",
    "# 최종 모델 초기화\n",
    "model_name = 'microsoft/deberta-v3-small'\n",
    "final_model = CrossEncoder(model_name, num_labels=1, device=device)\n",
    "\n",
    "# 전체 훈련 데이터로 예시 생성\n",
    "print(\"📚 전체 훈련 예시 생성 중...\")\n",
    "train_examples = []\n",
    "\n",
    "for i in tqdm(range(len(ce_inputs)), desc=\"최종 훈련 데이터 처리\"):\n",
    "    ce_input = ce_inputs[i]\n",
    "    \n",
    "    if '[댓글]' in ce_input:\n",
    "        rule_part = ce_input.split('[댓글]')[0].strip()\n",
    "        comment_part = ce_input.split('[댓글]')[1].strip()\n",
    "    else:\n",
    "        parts = ce_input.split()\n",
    "        mid = len(parts) // 2\n",
    "        rule_part = ' '.join(parts[:mid])\n",
    "        comment_part = ' '.join(parts[mid:])\n",
    "    \n",
    "    train_examples.append(\n",
    "        InputExample(texts=[rule_part, comment_part], label=float(labels[i]))\n",
    "    )\n",
    "\n",
    "# 최종 훈련 설정\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "warmup_steps = max(1, int(len(train_dataloader) * 0.1))\n",
    "\n",
    "print(f\"🚀 최종 모델 훈련 (에폭: 4, 배치: 16)\")\n",
    "\n",
    "# 최종 모델 훈련\n",
    "final_model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    epochs=4,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=output_model_path,\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a93bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 💾 모델 및 전처리 객체 저장\n",
    "print(\"💾 모델 및 전처리 객체 저장 중...\")\n",
    "\n",
    "# 모델 저장 경로 변수 사용\n",
    "output_dir = './model_output'\n",
    "\n",
    "# 1. Cross-Encoder 모델은 이미 output_path에 저장됨\n",
    "print(f\"✅ Cross-Encoder 모델 저장 완료: {os.path.abspath(output_dir)}/final_cross_encoder_model\")\n",
    "\n",
    "# 2. Scaler 저장\n",
    "joblib.dump(scaler, os.path.join(output_dir, 'scaler.pkl'))\n",
    "print(f\"✅ Scaler 저장 완료: {os.path.join(output_dir, 'scaler.pkl')}\")\n",
    "\n",
    "# 3. 수치 특징 컬럼명 저장\n",
    "with open(os.path.join(output_dir, 'numerical_cols.pkl'), 'wb') as f:\n",
    "    pickle.dump(numerical_cols, f)\n",
    "print(f\"✅ 수치 특징 컬럼명 저장 완료: {os.path.join(output_dir, 'numerical_cols.pkl')}\")\n",
    "\n",
    "# 4. 특징 엔지니어링 함수들을 포함한 유틸리티 저장\n",
    "feature_utils = {\n",
    "    'count_urls': count_urls,\n",
    "    'count_exclaims': count_exclaims,\n",
    "    'count_questions': count_questions,\n",
    "    'upper_ratio': upper_ratio,\n",
    "    'repeat_char_max': repeat_char_max,\n",
    "    'jaccard_similarity': jaccard_similarity,\n",
    "    'create_features': create_features,\n",
    "    'prepare_cross_encoder_input': prepare_cross_encoder_input\n",
    "}\n",
    "\n",
    "with open(os.path.join(output_dir, 'feature_utils.pkl'), 'wb') as f:\n",
    "    pickle.dump(feature_utils, f)\n",
    "print(f\"✅ 특징 엔지니어링 함수들 저장 완료: {os.path.join(output_dir, 'feature_utils.pkl')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffad6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 📋 저장된 파일들 확인\n",
    "output_dir = './model_output'\n",
    "print(f\"\\n📋 '{output_dir}' 폴더에 저장된 파일들:\")\n",
    "for file in os.listdir(output_dir):\n",
    "    file_path = os.path.join(output_dir, file)\n",
    "    if os.path.isfile(file_path):\n",
    "        file_size = os.path.getsize(file_path) / (1024*1024)  # MB\n",
    "        print(f\"  - {file}: {file_size:.2f} MB\")\n",
    "\n",
    "print(f\"\\n🎉 모델 학습 및 저장 완료!\")\n",
    "print(f\"📦 이제 '{output_dir}' 폴더에 저장된 파일들을 사용하여 추론을 진행할 수 있습니다.\")\n",
    "\n",
    "# 저장된 모델로 빠른 테스트\n",
    "print(\"\\n🧪 저장된 모델 빠른 테스트...\")\n",
    "test_rule = \"No spam or promotional content\"\n",
    "test_body = \"Check out this amazing deal! Buy now!\"\n",
    "\n",
    "test_input = prepare_cross_encoder_input(test_rule, test_body)\n",
    "if '[댓글]' in test_input:\n",
    "    rule_part = test_input.split('[댓글]')[0].strip()\n",
    "    comment_part = test_input.split('[댓글]')[1].strip()\n",
    "else:\n",
    "    parts = test_input.split()\n",
    "    mid = len(parts) // 2\n",
    "    rule_part = ' '.join(parts[:mid])\n",
    "    comment_part = ' '.join(parts[mid:])\n",
    "\n",
    "# 훈련이 끝난 final_model 변수를 사용하여 바로 예측\n",
    "test_pred = final_model.predict([[rule_part, comment_part]])\n",
    "test_prob = torch.sigmoid(torch.tensor(test_pred)).item()\n",
    "\n",
    "print(f\"테스트 규칙: {test_rule}\")\n",
    "print(f\"테스트 댓글: {test_body}\")\n",
    "print(f\"위반 확률: {test_prob:.4f}\")\n",
    "\n",
    "print(\"\\n✅ 모든 작업 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c025e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

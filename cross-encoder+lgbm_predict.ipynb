{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📝 Reddit 규칙 위반 탐지 앙상블 모델 추론\n",
    "\n",
    "이 노트북은 사전에 훈련된 **Cross-Encoder + LGBM 앙상블 모델**을 불러와 `test.csv` 데이터에 대한 예측을 수행하고, `submission.csv` 파일을 생성합니다.\n",
    "\n",
    "### **✅ 실행 전 확인 사항**\n",
    "1. **인터넷(Internet) OFF**: 노트북 설정에서 인터넷이 꺼져있는지 확인하세요.\n",
    "2. **데이터셋 추가**:\n",
    "    - **모델 데이터셋**: `model_output` 폴더가 포함된 Kaggle 데이터셋 (예: `my-rule-violation-ensemble-model`)\n",
    "    - **원본 데이터셋**: `test.csv`가 포함된 대회 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.sparse import hstack\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "# 경고 메시지 무시\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ 라이브러리 임포트 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1단계: 모델 및 전처리 객체 로드\n",
    "\n",
    "훈련 시 저장했던 모든 구성 요소(Cross-Encoder, LGBM 모델, Scaler, OneHotEncoder, 컬럼 리스트)를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 모델 및 객체가 저장된 경로 설정 ---\n",
    "# 본인의 Kaggle 데이터셋 경로에 맞게 수정해주세요.\n",
    "MODEL_PATH = '/kaggle/input/my-rule-violation-ensemble-model/model_output/'\n",
    "\n",
    "print(f\"모델 경로: {MODEL_PATH}\")\n",
    "\n",
    "# 1. Cross-Encoder 모델 로드\n",
    "cross_encoder_path = os.path.join(MODEL_PATH, 'final_cross_encoder_model')\n",
    "cross_encoder_model = CrossEncoder(cross_encoder_path)\n",
    "print(\"   - Cross-Encoder 모델 로드 완료\")\n",
    "\n",
    "# 2. LGBM 모델 로드\n",
    "lgbm_model = joblib.load(os.path.join(MODEL_PATH, 'lgbm_model.pkl'))\n",
    "print(\"   - LGBM 모델 로드 완료\")\n",
    "\n",
    "# 3. Scaler 및 OneHotEncoder 로드\n",
    "scaler = joblib.load(os.path.join(MODEL_PATH, 'scaler.pkl'))\n",
    "onehot_encoder = joblib.load(os.path.join(MODEL_PATH, 'onehot_encoder.pkl'))\n",
    "print(\"   - Scaler 및 OneHotEncoder 로드 완료\")\n",
    "\n",
    "# 4. 수치형 컬럼 리스트 로드\n",
    "with open(os.path.join(MODEL_PATH, 'numerical_cols.pkl'), 'rb') as f:\n",
    "    numerical_cols = pickle.load(f)\n",
    "print(\"   - 수치형 컬럼 리스트 로드 완료\")\n",
    "\n",
    "print(\"\\n✅ 모든 모델 및 전처리 객체 로딩 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2단계: 데이터 준비 및 특징 엔지니어링\n",
    "\n",
    "`test.csv`를 불러오고, 훈련 과정과 동일한 특징 엔지니어링 함수들을 정의하고 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 특징 엔지니어링 함수들 (훈련 노트북과 동일) ---\n",
    "def count_urls(text):\n",
    "    return len(re.findall(r'https?://\\S+|www\\.\\S+', str(text)))\n",
    "def count_exclaims(text):\n",
    "    return str(text).count('!')\n",
    "def count_questions(text):\n",
    "    return str(text).count('?')\n",
    "def upper_ratio(text):\n",
    "    s = str(text)\n",
    "    letters = [c for c in s if c.isalpha()]\n",
    "    if not letters: return 0.0\n",
    "    return sum(1 for c in letters if c.isupper()) / len(letters)\n",
    "def repeat_char_max(text):\n",
    "    longest = 1\n",
    "    last, cur = '', 0\n",
    "    for ch in str(text):\n",
    "        if ch == last: cur += 1\n",
    "        else: longest, cur, last = max(longest, cur), 1, ch\n",
    "    return max(longest, cur)\n",
    "def jaccard_similarity(text1, text2):\n",
    "    set1 = set(str(text1).lower().split())\n",
    "    set2 = set(str(text2).lower().split())\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['body_len'] = df['body'].astype(str).str.len()\n",
    "    df['rule_len'] = df['rule'].astype(str).str.len()\n",
    "    df['body_words'] = df['body'].astype(str).str.split().str.len()\n",
    "    df['url_cnt'] = df['body'].apply(count_urls)\n",
    "    df['exc_cnt'] = df['body'].apply(count_exclaims)\n",
    "    df['q_cnt'] = df['body'].apply(count_questions)\n",
    "    df['upper_rt'] = df['body'].apply(upper_ratio)\n",
    "    df['rep_run'] = df['body'].apply(repeat_char_max)\n",
    "    df['rule_body_jaccard'] = [jaccard_similarity(r, b) for r, b in zip(df['rule'], df['body'])]\n",
    "    return df\n",
    "\n",
    "def prepare_cross_encoder_input(rule, body, positive_ex1=None, negative_ex1=None):\n",
    "    rule_text, comment_text = str(rule).strip(), str(body).strip()\n",
    "    examples_text = \"\"\n",
    "    if pd.notna(positive_ex1) and str(positive_ex1).strip():\n",
    "        examples_text += f\" [긍정예시] {str(positive_ex1).strip()}\"\n",
    "    if pd.notna(negative_ex1) and str(negative_ex1).strip():\n",
    "        examples_text += f\" [부정예시] {str(negative_ex1).strip()}\"\n",
    "    return f\"[규칙] {rule_text}{examples_text} [댓글] {comment_text}\"\n",
    "\n",
    "# --- test.csv 로드 및 전처리 실행 ---\n",
    "test_df = pd.read_csv('/kaggle/input/reddit-rule-violation-prediction/test.csv')\n",
    "print(\"test.csv 로드 완료.\")\n",
    "\n",
    "test_df_featured = create_features(test_df)\n",
    "print(\"특징 엔지니어링 완료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3단계: 예측 실행 및 제출 파일 생성\n",
    "\n",
    "전체 파이프라인을 순서대로 실행하여 최종 예측 확률을 계산하고 `submission.csv` 파일을 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Cross-Encoder 입력 준비 및 예측 ---\n",
    "print(\"1/4: Cross-Encoder 입력 준비 중...\")\n",
    "test_ce_inputs = []\n",
    "for row in tqdm(test_df.itertuples(), total=len(test_df)):\n",
    "    test_ce_inputs.append(prepare_cross_encoder_input(\n",
    "        row.rule, row.body, \n",
    "        getattr(row, 'positive_example_1', None), \n",
    "        getattr(row, 'negative_example_1', None)\n",
    "    ))\n",
    "\n",
    "test_predict_examples = []\n",
    "for ce_input in test_ce_inputs:\n",
    "    if '[댓글]' in ce_input:\n",
    "        rule_part, comment_part = ce_input.split('[댓글]', 1)\n",
    "        test_predict_examples.append([rule_part.strip(), comment_part.strip()])\n",
    "    else:\n",
    "        test_predict_examples.append([ce_input.strip(), \"\"])\n",
    "\n",
    "print(\"2/4: Cross-Encoder로 semantic score 예측 중...\")\n",
    "test_ce_scores = cross_encoder_model.predict(test_predict_examples, show_progress_bar=True, batch_size=64)\n",
    "test_df_featured['ce_score'] = test_ce_scores\n",
    "\n",
    "# --- 2. LGBM 입력 준비 ---\n",
    "print(\"3/4: LGBM 입력을 위한 데이터 변환 중...\")\n",
    "test_numerical_features = scaler.transform(test_df_featured[numerical_cols])\n",
    "test_categorical_features = onehot_encoder.transform(test_df_featured[['subreddit']])\n",
    "X_test_lgbm = hstack([test_numerical_features, test_categorical_features])\n",
    "\n",
    "# --- 3. 최종 예측 및 제출 파일 생성 ---\n",
    "print(\"4/4: 최종 예측 및 제출 파일 생성 중...\")\n",
    "final_predictions_proba = lgbm_model.predict_proba(X_test_lgbm)[:, 1]\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'row_id': test_df['row_id'],\n",
    "    'rule_violation': final_predictions_proba\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\n🎉 모든 작업 완료! `submission.csv` 파일이 생성되었습니다.\")\n",
    "print(\"생성된 파일 샘플:\")\n",
    "display(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "969484a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01_create_embeddings_for_kaggle.ipynb\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# --- 설정 ---\n",
    "# Hugging Face에서 사용할 임베딩 모델 이름\n",
    "MODEL_NAME = \"BAAI/bge-large-en-v1.5\" \n",
    "\n",
    "# 캐글 Competition 데이터 경로\n",
    "# 이 경로는 캐글에서 데이터를 추가했을 때의 기본 경로입니다.\n",
    "# COMPETITION_DATA_PATH = \"/kaggle/input/jigsaw-agile-community-rules\"\n",
    "# TRAIN_DATA_PATH = os.path.join(COMPETITION_DATA_PATH, \"train.csv\")\n",
    "# TEST_DATA_PATH = os.path.join(COMPETITION_DATA_PATH, \"test.csv\")\n",
    "TRAIN_DATA_PATH = \"train.csv\"\n",
    "TEST_DATA_PATH = \"test.csv\"\n",
    "\n",
    "# 캐글 노트북의 출력 폴더 경로\n",
    "# 이 경로에 저장된 파일만 데이터셋으로 만들 수 있습니다.\n",
    "OUTPUT_DIR = \"working\" \n",
    "EMBEDDINGS_SAVE_PATH = os.path.join(OUTPUT_DIR, \"reference_embeddings.npy\")\n",
    "LABELS_SAVE_PATH = os.path.join(OUTPUT_DIR, \"reference_labels.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b8682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 1. 환경 설정 및 모델 로딩 시작\n",
      "'BAAI/bge-large-en-v1.5' 모델을 다운로드하고 로딩합니다...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 cuda에 로딩되었습니다.\n",
      "GPU 사용이 가능하여 모델을 half-precision(float16)으로 변환했습니다.\n",
      ">>> 모델 로딩 완료!\n",
      "\n",
      ">>> 2. 데이터 로딩 시작\n",
      "train.csv와 test.csv 파일을 성공적으로 불러왔습니다.\n",
      ">>> 데이터 로딩 완료!\n",
      "\n",
      ">>> 4. 참조 임베딩 생성 시작\n",
      "훈련 데이터로부터 참조 텍스트를 생성합니다...\n",
      "훈련 데이터에서 1998개의 샘플을 추가했습니다.\n",
      "테스트 데이터의 예시를 추가하여 총 2038개의 참조 텍스트를 생성했습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "임베딩 생성 중: 100%|██████████| 128/128 [00:13<00:00,  9.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- 1. 환경 설정 및 모델 로딩 ---\n",
    "# (이전 코드와 동일)\n",
    "print(\">>> 1. 환경 설정 및 모델 로딩 시작\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"'{MODEL_NAME}' 모델을 다운로드하고 로딩합니다...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "base_model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "base_model.to(device)\n",
    "print(f\"모델이 {device}에 로딩되었습니다.\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    base_model = base_model.half()\n",
    "    print(\"GPU 사용이 가능하여 모델을 half-precision(float16)으로 변환했습니다.\")\n",
    "print(\">>> 모델 로딩 완료!\\n\")\n",
    "\n",
    "\n",
    "# --- 2. 데이터 로딩 ---\n",
    "print(\">>> 2. 데이터 로딩 시작\")\n",
    "train = pd.read_csv(TRAIN_DATA_PATH)\n",
    "test = pd.read_csv(TEST_DATA_PATH)\n",
    "print(\"train.csv와 test.csv 파일을 성공적으로 불러왔습니다.\")\n",
    "\n",
    "MAX_TRAIN_SAMPLES = 10000 \n",
    "if len(train) > MAX_TRAIN_SAMPLES:\n",
    "    train = train.sample(n=MAX_TRAIN_SAMPLES, random_state=42)\n",
    "    print(f\"훈련 데이터가 너무 커서 {MAX_TRAIN_SAMPLES}개로 샘플링되었습니다.\")\n",
    "print(\">>> 데이터 로딩 완료!\\n\")\n",
    "\n",
    "\n",
    "# --- 3. 헬퍼 함수 정의 ---\n",
    "# (get_embeddings_optimized, create_smart_reference_texts 함수는 이전 코드와 동일)\n",
    "def get_embeddings_optimized(texts, model, tokenizer, device, batch_size=16, max_length=512):\n",
    "    \"\"\"주어진 텍스트 목록을 임베딩 벡터로 변환하는 함수 (최적화 버전)\"\"\"\n",
    "    embeddings = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(texts), batch_size), desc=\"임베딩 생성 중\"):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            batch_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "            batch_embeddings = batch_embeddings.float().cpu().numpy()\n",
    "            embeddings.append(batch_embeddings)\n",
    "            if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    \n",
    "    return np.vstack(embeddings)\n",
    "\n",
    "def create_smart_reference_texts(train_df, test_df, max_per_category=1000):\n",
    "    \"\"\"예측의 기준이 될 '참조 텍스트'와 라벨을 생성하는 함수\"\"\"\n",
    "    reference_texts, reference_labels = [], []\n",
    "    print(\"훈련 데이터로부터 참조 텍스트를 생성합니다...\")\n",
    "    violation_samples = train_df[train_df['rule_violation'] == 1].sample(min(len(train_df[train_df['rule_violation'] == 1]), max_per_category), random_state=42)\n",
    "    non_violation_samples = train_df[train_df['rule_violation'] == 0].sample(min(len(train_df[train_df['rule_violation'] == 0]), max_per_category), random_state=42)\n",
    "    balanced_train = pd.concat([violation_samples, non_violation_samples])\n",
    "    for _, row in balanced_train.iterrows():\n",
    "        reference_texts.append(f\"r/{row['subreddit']}\\nRule: {row['rule']}\\nComment: {row['body']}\")\n",
    "        reference_labels.append(row['rule_violation'])\n",
    "    print(f\"훈련 데이터에서 {len(reference_texts)}개의 샘플을 추가했습니다.\")\n",
    "    sample_test = test_df.sample(min(len(test_df), 500), random_state=42)\n",
    "    for _, row in sample_test.iterrows():\n",
    "        rule_text = f\"r/{row['subreddit']}\\nRule: {row['rule']}\\n\"\n",
    "        for i in [1, 2]:\n",
    "            if pd.notna(row.get(f'positive_example_{i}')):\n",
    "                reference_texts.append(rule_text + f\"Comment: {row[f'positive_example_{i}']}\")\n",
    "                reference_labels.append(1)\n",
    "        for i in [1, 2]:\n",
    "            if pd.notna(row.get(f'negative_example_{i}')):\n",
    "                reference_texts.append(rule_text + f\"Comment: {row[f'negative_example_{i}']}\")\n",
    "                reference_labels.append(0)\n",
    "    print(f\"테스트 데이터의 예시를 추가하여 총 {len(reference_texts)}개의 참조 텍스트를 생성했습니다.\")\n",
    "    return reference_texts, reference_labels\n",
    "\n",
    "# --- 4. 메인 실행 로직 ---\n",
    "print(\">>> 4. 참조 임베딩 생성 시작\")\n",
    "reference_texts, reference_labels = create_smart_reference_texts(train, test)\n",
    "reference_embeddings = get_embeddings_optimized(reference_texts, base_model, tokenizer, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b97353c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 임베딩과 라벨을 'working' 폴더에 저장합니다...\n",
      ">>> 모든 작업 완료! ✨\n",
      "'working/reference_embeddings.npy' 와 'working/reference_labels.npy' 파일이 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 1. 저장하기 전에 출력 폴더가 있는지 확인하고, 없으면 생성합니다.\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True) \n",
    "print(f\"생성된 임베딩과 라벨을 '{OUTPUT_DIR}' 폴더에 저장합니다...\")\n",
    "\n",
    "# 2. 넘파이(Numpy) 배열을 바이너리 파일(.npy) 형태로 저장합니다.\n",
    "np.save(EMBEDDINGS_SAVE_PATH, reference_embeddings)\n",
    "np.save(LABELS_SAVE_PATH, np.array(reference_labels))\n",
    "\n",
    "# 3. 로컬 환경에 맞는 완료 메시지를 출력합니다.\n",
    "print(\">>> 모든 작업 완료! ✨\")\n",
    "print(f\"'{EMBEDDINGS_SAVE_PATH}' 와 '{LABELS_SAVE_PATH}' 파일이 성공적으로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18590b87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df622495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cache_dir = \"C:/huggingface_cache\"\n",
    "os.environ['HF_HOME'] = cache_dir\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir # 만약을 위해 이중으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1781db68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용 가능: True\n",
      "사용 디바이스: cuda\n"
     ]
    }
   ],
   "source": [
    "# 📚 필수 라이브러리 설치 및 임포트\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# Kaggle 입력 데이터 확인\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"GPU 사용 가능: {torch.cuda.is_available()}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"사용 디바이스: {device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c83e6f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 데이터 형태: (2029, 9)\n",
      "🎯 타겟 분포: {1: 1031, 0: 998}\n",
      "\n",
      "📋 데이터 샘플:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>body</th>\n",
       "      <th>rule</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>positive_example_1</th>\n",
       "      <th>positive_example_2</th>\n",
       "      <th>negative_example_1</th>\n",
       "      <th>negative_example_2</th>\n",
       "      <th>rule_violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Banks don't want you to know this! Click here ...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>Futurology</td>\n",
       "      <td>If you could tell your younger self something ...</td>\n",
       "      <td>hunt for lady for jack off in neighbourhood ht...</td>\n",
       "      <td>Watch Golden Globe Awards 2017 Live Online in ...</td>\n",
       "      <td>DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SD Stream [ ENG Link 1] (http://www.sportsstre...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>soccerstreams</td>\n",
       "      <td>[I wanna kiss you all over! Stunning!](http://...</td>\n",
       "      <td>LOLGA.COM is One of the First Professional Onl...</td>\n",
       "      <td>#Rapper \\n🚨Straight Outta Cross Keys SC 🚨YouTu...</td>\n",
       "      <td>[15 Amazing Hidden Features Of Google Search Y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Lol. Try appealing the ban and say you won't d...</td>\n",
       "      <td>No legal advice: Do not offer or request legal...</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td>Don't break up with him or call the cops.  If ...</td>\n",
       "      <td>It'll be dismissed: https://en.wikipedia.org/w...</td>\n",
       "      <td>Where is there a site that still works where y...</td>\n",
       "      <td>Because this statement of his is true. It isn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>she will come your home open her legs with  an...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>sex</td>\n",
       "      <td>Selling Tyrande codes for 3€ to paypal. PM. \\n...</td>\n",
       "      <td>tight pussy watch for your cock get her at thi...</td>\n",
       "      <td>NSFW(obviously) http://spankbang.com/iy3u/vide...</td>\n",
       "      <td>Good News ::Download WhatsApp 2.16.230 APK for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>code free tyrande ---&gt;&gt;&gt; [Imgur](http://i.imgu...</td>\n",
       "      <td>No Advertising: Spam, referral links, unsolici...</td>\n",
       "      <td>hearthstone</td>\n",
       "      <td>wow!! amazing reminds me of the old days.Well...</td>\n",
       "      <td>seek for lady for sex in around http://p77.pl/...</td>\n",
       "      <td>must be watch movie https://sites.google.com/s...</td>\n",
       "      <td>We're streaming Pokemon Veitnamese Crystal RIG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id                                               body  \\\n",
       "0       0  Banks don't want you to know this! Click here ...   \n",
       "1       1  SD Stream [ ENG Link 1] (http://www.sportsstre...   \n",
       "2       2  Lol. Try appealing the ban and say you won't d...   \n",
       "3       3  she will come your home open her legs with  an...   \n",
       "4       4  code free tyrande --->>> [Imgur](http://i.imgu...   \n",
       "\n",
       "                                                rule      subreddit  \\\n",
       "0  No Advertising: Spam, referral links, unsolici...     Futurology   \n",
       "1  No Advertising: Spam, referral links, unsolici...  soccerstreams   \n",
       "2  No legal advice: Do not offer or request legal...   pcmasterrace   \n",
       "3  No Advertising: Spam, referral links, unsolici...            sex   \n",
       "4  No Advertising: Spam, referral links, unsolici...    hearthstone   \n",
       "\n",
       "                                  positive_example_1  \\\n",
       "0  If you could tell your younger self something ...   \n",
       "1  [I wanna kiss you all over! Stunning!](http://...   \n",
       "2  Don't break up with him or call the cops.  If ...   \n",
       "3  Selling Tyrande codes for 3€ to paypal. PM. \\n...   \n",
       "4   wow!! amazing reminds me of the old days.Well...   \n",
       "\n",
       "                                  positive_example_2  \\\n",
       "0  hunt for lady for jack off in neighbourhood ht...   \n",
       "1  LOLGA.COM is One of the First Professional Onl...   \n",
       "2  It'll be dismissed: https://en.wikipedia.org/w...   \n",
       "3  tight pussy watch for your cock get her at thi...   \n",
       "4  seek for lady for sex in around http://p77.pl/...   \n",
       "\n",
       "                                  negative_example_1  \\\n",
       "0  Watch Golden Globe Awards 2017 Live Online in ...   \n",
       "1  #Rapper \\n🚨Straight Outta Cross Keys SC 🚨YouTu...   \n",
       "2  Where is there a site that still works where y...   \n",
       "3  NSFW(obviously) http://spankbang.com/iy3u/vide...   \n",
       "4  must be watch movie https://sites.google.com/s...   \n",
       "\n",
       "                                  negative_example_2  rule_violation  \n",
       "0  DOUBLE CEE x BANDS EPPS - \"BIRDS\"\\n\\nDOWNLOAD/...               0  \n",
       "1  [15 Amazing Hidden Features Of Google Search Y...               0  \n",
       "2  Because this statement of his is true. It isn'...               1  \n",
       "3  Good News ::Download WhatsApp 2.16.230 APK for...               1  \n",
       "4  We're streaming Pokemon Veitnamese Crystal RIG...               1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 📊 데이터 로드 및 기본 정보 확인\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "print(f\"🔍 데이터 형태: {train_df.shape}\")\n",
    "print(f\"🎯 타겟 분포: {train_df['rule_violation'].value_counts().to_dict()}\")\n",
    "print(\"\\n📋 데이터 샘플:\")\n",
    "display(train_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66819f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 데이터 전처리 시작...\n",
      "📏 기본 텍스트 특징 생성 중...\n",
      "🎨 스타일 특징 생성 중...\n",
      "😊 이모지 및 특수문자 특징 생성 중...\n",
      "📚 어휘 기반 특징 생성 중...\n",
      "🔗 규칙-댓글 상호작용 특징 생성 중...\n",
      "✅ 특징 생성 완료!\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 🛠️ 특징 엔지니어링 함수 정의\n",
    "def count_urls(text):\n",
    "    \"\"\"URL 개수 세기\"\"\"\n",
    "    return len(re.findall(r'https?://\\S+|www\\.\\S+', str(text)))\n",
    "\n",
    "def count_exclaims(text):\n",
    "    \"\"\"감탄표 개수 세기\"\"\"\n",
    "    return str(text).count('!')\n",
    "\n",
    "def count_questions(text):\n",
    "    \"\"\"물음표 개수 세기\"\"\"\n",
    "    return str(text).count('?')\n",
    "\n",
    "def upper_ratio(text):\n",
    "    \"\"\"대문자 비율 계산\"\"\"\n",
    "    s = str(text)\n",
    "    letters = [c for c in s if c.isalpha()]\n",
    "    if not letters:\n",
    "        return 0.0\n",
    "    upp = sum(1 for c in letters if c.isupper())\n",
    "    return upp / len(letters)\n",
    "\n",
    "def repeat_char_max(text):\n",
    "    \"\"\"연속된 문자의 최대 길이\"\"\"\n",
    "    longest = 1\n",
    "    last = ''\n",
    "    cur = 0\n",
    "    for ch in str(text):\n",
    "        if ch == last:\n",
    "            cur += 1\n",
    "        else:\n",
    "            longest = max(longest, cur)\n",
    "            cur = 1\n",
    "            last = ch\n",
    "    longest = max(longest, cur)\n",
    "    return longest\n",
    "\n",
    "def jaccard_similarity(text1, text2):\n",
    "    \"\"\"자카드 유사도 계산\"\"\"\n",
    "    set1 = set(str(text1).lower().split())\n",
    "    set2 = set(str(text2).lower().split())\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "# ==========================================================\n",
    "# 🔧 특징 생성 함수\n",
    "def create_features(df):\n",
    "    \"\"\"EDA에서 발견한 유용한 특징들을 생성\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    print(\"📏 기본 텍스트 특징 생성 중...\")\n",
    "    df['body_len'] = df['body'].astype(str).str.len()\n",
    "    df['rule_len'] = df['rule'].astype(str).str.len()\n",
    "    df['body_words'] = df['body'].astype(str).str.split().str.len()\n",
    "    \n",
    "    print(\"🎨 스타일 특징 생성 중...\")\n",
    "    df['url_cnt'] = df['body'].apply(count_urls)\n",
    "    df['exc_cnt'] = df['body'].apply(count_exclaims)\n",
    "    df['q_cnt'] = df['body'].apply(count_questions)\n",
    "    df['upper_rt'] = df['body'].apply(upper_ratio)\n",
    "    df['rep_run'] = df['body'].apply(repeat_char_max)\n",
    "    \n",
    "    print(\"😊 이모지 및 특수문자 특징 생성 중...\")\n",
    "    emoji_set = set(\"😀😃😄😁😆😅😂🤣🥲😊🙂🙃😉😍😘😗😙😚😋😛😝😜🤪🤨🧐🤓😎🤩🥳😏😒😞😔😟😕🙁☹️😣😖😫😩😤😠😡🤬\")\n",
    "    df['emoji_rt'] = df['body'].apply(\n",
    "        lambda s: sum(1 for ch in str(s) if ch in emoji_set) / max(len(str(s)), 1)\n",
    "    )\n",
    "    \n",
    "    print(\"📚 어휘 기반 특징 생성 중...\")\n",
    "    profanity_words = {'idiot', 'moron', 'stupid', 'dumb', 'retard', 'asshole', \n",
    "                      'bastard', 'fuck', 'shit', 'damn', 'bitch'}\n",
    "    ad_words = {'free', 'win', 'offer', 'discount', 'promo', 'sale', 'subscribe',\n",
    "                'click', 'visit', 'buy', 'deal', 'coupon', 'limited'}\n",
    "    \n",
    "    df['has_profanity'] = df['body'].apply(\n",
    "        lambda x: int(any(word in str(x).lower() for word in profanity_words))\n",
    "    )\n",
    "    df['has_adword'] = df['body'].apply(\n",
    "        lambda x: int(any(word in str(x).lower() for word in ad_words))\n",
    "    )\n",
    "    \n",
    "    print(\"🔗 규칙-댓글 상호작용 특징 생성 중...\")\n",
    "    df['rule_body_jaccard'] = [\n",
    "        jaccard_similarity(rule, body) \n",
    "        for rule, body in zip(df['rule'], df['body'])\n",
    "    ]\n",
    "    \n",
    "    print(\"✅ 특징 생성 완료!\")\n",
    "    return df\n",
    "\n",
    "# ==========================================================\n",
    "# 🤖 Cross-Encoder 입력 준비 함수\n",
    "def prepare_cross_encoder_input(rule, body, positive_ex1=None, positive_ex2=None, \n",
    "                               negative_ex1=None, negative_ex2=None):\n",
    "    \"\"\"Cross-Encoder를 위한 입력 텍스트 준비\"\"\"\n",
    "    rule_text = str(rule).strip()\n",
    "    comment_text = str(body).strip()\n",
    "    \n",
    "    examples_text = \"\"\n",
    "    if pd.notna(positive_ex1) and str(positive_ex1).strip():\n",
    "        examples_text += f\" [긍정예시] {str(positive_ex1).strip()}\"\n",
    "    if pd.notna(negative_ex1) and str(negative_ex1).strip():\n",
    "        examples_text += f\" [부정예시] {str(negative_ex1).strip()}\"\n",
    "    \n",
    "    full_input = f\"[규칙] {rule_text}{examples_text} [댓글] {comment_text}\"\n",
    "    return full_input\n",
    "\n",
    "# ==========================================================\n",
    "# 📊 데이터 전처리 및 특징 생성\n",
    "print(\"🔧 데이터 전처리 시작...\")\n",
    "\n",
    "# 특징 생성 실행\n",
    "train_df = create_features(train_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb6d6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Cross-Encoder 입력 데이터 준비 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "입력 데이터 처리: 100%|██████████| 2029/2029 [00:00<00:00, 17049.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 2029개의 Cross-Encoder 입력 쌍 준비 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 수치 특징 정의\n",
    "numerical_cols = [\n",
    "    'body_len', 'rule_len', 'body_words', 'url_cnt', 'exc_cnt', 'q_cnt',\n",
    "    'upper_rt', 'rep_run', 'emoji_rt', 'has_profanity', 'has_adword', \n",
    "    'rule_body_jaccard'\n",
    "]\n",
    "\n",
    "# 수치 특징 정규화\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "numerical_features = scaler.fit_transform(train_df[numerical_cols])\n",
    "\n",
    "# Cross-Encoder 입력 데이터 준비\n",
    "print(\"🔄 Cross-Encoder 입력 데이터 준비 중...\")\n",
    "ce_inputs = []\n",
    "labels = []\n",
    "\n",
    "for idx, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"입력 데이터 처리\"):\n",
    "    ce_input = prepare_cross_encoder_input(\n",
    "        row['rule'], \n",
    "        row['body'],\n",
    "        row.get('positive_example_1'),\n",
    "        row.get('positive_example_2'),\n",
    "        row.get('negative_example_1'),\n",
    "        row.get('negative_example_2')\n",
    "    )\n",
    "    ce_inputs.append(ce_input)\n",
    "    labels.append(int(row['rule_violation']))\n",
    "\n",
    "ce_inputs = np.array(ce_inputs)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"✅ {len(ce_inputs)}개의 Cross-Encoder 입력 쌍 준비 완료\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bea179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏗️ 전체 데이터셋으로 최종 모델 훈련 시작!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 전체 훈련 예시 생성 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "최종 훈련 데이터 처리: 100%|██████████| 2029/2029 [00:00<00:00, 156042.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 최종 모델 훈련 (에폭: 4, 배치: 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Iteration: 100%|██████████| 127/127 [03:44<00:00,  1.76s/it]\n",
      "Epoch:  25%|██▌       | 1/4 [03:44<11:12, 224.10s/it]"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 🏗️ 최종 모델 훈련 (전체 데이터 사용)\n",
    "from sentence_transformers import CrossEncoder, InputExample\n",
    "\n",
    "print(\"🏗️ 전체 데이터셋으로 최종 모델 훈련 시작!\")\n",
    "\n",
    "# 최종 모델 초기화\n",
    "model_name = 'microsoft/deberta-v3-small'\n",
    "final_model = CrossEncoder(model_name, num_labels=1, device=device)\n",
    "\n",
    "# 전체 훈련 데이터로 예시 생성\n",
    "print(\"📚 전체 훈련 예시 생성 중...\")\n",
    "train_examples = []\n",
    "\n",
    "for i in tqdm(range(len(ce_inputs)), desc=\"최종 훈련 데이터 처리\"):\n",
    "    ce_input = ce_inputs[i]\n",
    "    \n",
    "    if '[댓글]' in ce_input:\n",
    "        rule_part = ce_input.split('[댓글]')[0].strip()\n",
    "        comment_part = ce_input.split('[댓글]')[1].strip()\n",
    "    else:\n",
    "        parts = ce_input.split()\n",
    "        mid = len(parts) // 2\n",
    "        rule_part = ' '.join(parts[:mid])\n",
    "        comment_part = ' '.join(parts[mid:])\n",
    "    \n",
    "    train_examples.append(\n",
    "        InputExample(texts=[rule_part, comment_part], label=float(labels[i]))\n",
    "    )\n",
    "\n",
    "# 최종 훈련 설정\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "warmup_steps = max(1, int(len(train_dataloader) * 0.1))\n",
    "\n",
    "print(f\"🚀 최종 모델 훈련 (에폭: 4, 배치: 16)\")\n",
    "\n",
    "# 최종 모델 훈련\n",
    "final_model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    epochs=4,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path='/kaggle/working/final_cross_encoder_model',\n",
    "    save_best_model=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a93bb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 💾 모델 및 전처리 객체 저장\n",
    "print(\"💾 모델 및 전처리 객체 저장 중...\")\n",
    "\n",
    "# 1. Cross-Encoder 모델은 이미 output_path에 저장됨\n",
    "print(\"✅ Cross-Encoder 모델 저장 완료: /kaggle/working/final_cross_encoder_model\")\n",
    "\n",
    "# 2. Scaler 저장\n",
    "joblib.dump(scaler, '/kaggle/working/scaler.pkl')\n",
    "print(\"✅ Scaler 저장 완료: /kaggle/working/scaler.pkl\")\n",
    "\n",
    "# 3. 수치 특징 컬럼명 저장\n",
    "with open('/kaggle/working/numerical_cols.pkl', 'wb') as f:\n",
    "    pickle.dump(numerical_cols, f)\n",
    "print(\"✅ 수치 특징 컬럼명 저장 완료: /kaggle/working/numerical_cols.pkl\")\n",
    "\n",
    "# 4. 특징 엔지니어링 함수들을 포함한 유틸리티 저장\n",
    "feature_utils = {\n",
    "    'count_urls': count_urls,\n",
    "    'count_exclaims': count_exclaims,\n",
    "    'count_questions': count_questions,\n",
    "    'upper_ratio': upper_ratio,\n",
    "    'repeat_char_max': repeat_char_max,\n",
    "    'jaccard_similarity': jaccard_similarity,\n",
    "    'create_features': create_features,\n",
    "    'prepare_cross_encoder_input': prepare_cross_encoder_input\n",
    "}\n",
    "\n",
    "with open('/kaggle/working/feature_utils.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_utils, f)\n",
    "print(\"✅ 특징 엔지니어링 함수들 저장 완료: /kaggle/working/feature_utils.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffad6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 📋 저장된 파일들 확인\n",
    "print(\"\\n📋 저장된 파일들:\")\n",
    "for file in os.listdir('/kaggle/working'):\n",
    "    if file.endswith(('.pkl', '.bin', '.json', '.txt')) or 'model' in file:\n",
    "        file_path = f'/kaggle/working/{file}'\n",
    "        file_size = os.path.getsize(file_path) / (1024*1024)  # MB\n",
    "        print(f\"  - {file}: {file_size:.2f} MB\")\n",
    "\n",
    "print(f\"\\n🎉 모델 학습 및 저장 완료!\")\n",
    "print(f\"📦 이제 이 파일들을 Kaggle Dataset으로 업로드하여 추론 노트북에서 사용하세요.\")\n",
    "print(f\"📁 업로드할 폴더: /kaggle/working/\")\n",
    "\n",
    "# 저장된 모델로 빠른 테스트\n",
    "print(\"\\n🧪 저장된 모델 빠른 테스트...\")\n",
    "test_rule = \"No spam or promotional content\"\n",
    "test_body = \"Check out this amazing deal! Buy now!\"\n",
    "\n",
    "test_input = prepare_cross_encoder_input(test_rule, test_body)\n",
    "if '[댓글]' in test_input:\n",
    "    rule_part = test_input.split('[댓글]')[0].strip()\n",
    "    comment_part = test_input.split('[댓글]')[1].strip()\n",
    "else:\n",
    "    parts = test_input.split()\n",
    "    mid = len(parts) // 2\n",
    "    rule_part = ' '.join(parts[:mid])\n",
    "    comment_part = ' '.join(parts[mid:])\n",
    "\n",
    "test_pred = final_model.predict([[rule_part, comment_part]])\n",
    "test_prob = torch.sigmoid(torch.tensor(test_pred)).item()\n",
    "\n",
    "print(f\"테스트 규칙: {test_rule}\")\n",
    "print(f\"테스트 댓글: {test_body}\")\n",
    "print(f\"위반 확률: {test_prob:.4f}\")\n",
    "\n",
    "print(\"\\n✅ 모든 작업 완료!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
